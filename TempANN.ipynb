{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 14:14:28.263220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PIMA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2      138             62             35        0  33.6   \n",
       "1               0       84             82             31      125  38.2   \n",
       "2               0      145              0              0        0  44.2   \n",
       "3               0      135             68             42      250  42.3   \n",
       "4               1      139             62             41      480  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2       75             64             24       55  29.7   \n",
       "1996            8      179             72             42      130  32.7   \n",
       "1997            6       85             78              0        0  31.2   \n",
       "1998            0      129            110             46      130  67.1   \n",
       "1999            2       81             72             15       76  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.703500</td>\n",
       "      <td>121.182500</td>\n",
       "      <td>69.145500</td>\n",
       "      <td>20.935000</td>\n",
       "      <td>80.254000</td>\n",
       "      <td>32.193000</td>\n",
       "      <td>0.470930</td>\n",
       "      <td>33.090500</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.306063</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>0.474498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies      Glucose  BloodPressure  SkinThickness      Insulin  \\\n",
       "count  2000.000000  2000.000000    2000.000000    2000.000000  2000.000000   \n",
       "mean      3.703500   121.182500      69.145500      20.935000    80.254000   \n",
       "std       3.306063    32.068636      19.188315      16.103243   111.180534   \n",
       "min       0.000000     0.000000       0.000000       0.000000     0.000000   \n",
       "25%       1.000000    99.000000      63.500000       0.000000     0.000000   \n",
       "50%       3.000000   117.000000      72.000000      23.000000    40.000000   \n",
       "75%       6.000000   141.000000      80.000000      32.000000   130.000000   \n",
       "max      17.000000   199.000000     122.000000     110.000000   744.000000   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction          Age      Outcome  \n",
       "count  2000.000000               2000.000000  2000.000000  2000.000000  \n",
       "mean     32.193000                  0.470930    33.090500     0.342000  \n",
       "std       8.149901                  0.323553    11.786423     0.474498  \n",
       "min       0.000000                  0.078000    21.000000     0.000000  \n",
       "25%      27.375000                  0.244000    24.000000     0.000000  \n",
       "50%      32.300000                  0.376000    29.000000     0.000000  \n",
       "75%      36.800000                  0.624000    40.000000     1.000000  \n",
       "max      80.600000                  2.420000    81.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['DiabetesPedigreeFunction'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  Age  \\\n",
       "0               2      138             62             35        0  33.6   47   \n",
       "1               0       84             82             31      125  38.2   23   \n",
       "2               0      145              0              0        0  44.2   31   \n",
       "3               0      135             68             42      250  42.3   24   \n",
       "4               1      139             62             41      480  40.7   21   \n",
       "...           ...      ...            ...            ...      ...   ...  ...   \n",
       "1995            2       75             64             24       55  29.7   33   \n",
       "1996            8      179             72             42      130  32.7   36   \n",
       "1997            6       85             78              0        0  31.2   42   \n",
       "1998            0      129            110             46      130  67.1   26   \n",
       "1999            2       81             72             15       76  30.1   25   \n",
       "\n",
       "      Outcome  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "...       ...  \n",
       "1995        0  \n",
       "1996        1  \n",
       "1997        0  \n",
       "1998        1  \n",
       "1999        0  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Pregnancies    2000 non-null   int64  \n",
      " 1   Glucose        2000 non-null   int64  \n",
      " 2   BloodPressure  2000 non-null   int64  \n",
      " 3   SkinThickness  2000 non-null   int64  \n",
      " 4   Insulin        2000 non-null   int64  \n",
      " 5   BMI            2000 non-null   float64\n",
      " 6   Age            2000 non-null   int64  \n",
      " 7   Outcome        2000 non-null   int64  \n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies      0\n",
       "Glucose          0\n",
       "BloodPressure    0\n",
       "SkinThickness    0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Age              0\n",
       "Outcome          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,14))\n",
    "# sns.boxplot(data=df)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(13,13))\n",
    "# for colName in df.columns:\n",
    "#     plt.figure()\n",
    "#     sns.scatterplot(data=df[colName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35730/684818280.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
      "/tmp/ipykernel_35730/684818280.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan\n"
     ]
    }
   ],
   "source": [
    "df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
    "df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies       0\n",
       "Glucose          15\n",
       "BloodPressure    95\n",
       "SkinThickness     0\n",
       "Insulin           0\n",
       "BMI               0\n",
       "Age               0\n",
       "Outcome           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BloodPressure'].isnull().sum()/len(df['BloodPressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies      0\n",
       "Glucose          0\n",
       "BloodPressure    0\n",
       "SkinThickness    0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Age              0\n",
       "Outcome          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2. , 138. ,  62. , ...,   0. ,  33.6,  47. ],\n",
       "       [  0. ,  84. ,  82. , ..., 125. ,  38.2,  23. ],\n",
       "       [  0. , 135. ,  68. , ..., 250. ,  42.3,  24. ],\n",
       "       ...,\n",
       "       [  6. ,  85. ,  78. , ...,   0. ,  31.2,  42. ],\n",
       "       [  0. , 129. , 110. , ..., 130. ,  67.1,  26. ],\n",
       "       [  2. ,  81. ,  72. , ...,  76. ,  30.1,  25. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1 = StandardScaler()\n",
    "sc1.fit(X_train)\n",
    "X_test = sc1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('scalers/standardScaler.pkl','wb') as f:\n",
    "#     pickle.dump(sc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=75, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=79, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=57, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# # ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=101, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=89, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=37, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=131, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=274, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=479, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=389, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=59, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 14:14:33.427621: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-11 14:14:33.428229: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-11 14:14:33.428249: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-11 14:14:33.428278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (RSPL-346): /proc/driver/nvidia/version does not exist\n",
      "2022-04-11 14:14:33.428541: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-11 14:14:33.429202: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=132, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=279, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=423, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=579, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=456, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=303, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=154, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "ann.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall')\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# accuracies = cross_val_score(estimator=ann, X=X_train, y=y_train, cv= 10)\n",
    "# print(f'Accuracies: {accuracies}')\n",
    "# print('Mean Accuracy: {:.2f}'.format(accuracies.mean()))\n",
    "# print('Standard Deviation of Accuracies: {:.2f}'.format(accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 14:14:33.709857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-11 14:14:33.730281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 1s 10ms/step - loss: 0.6534 - accuracy: 0.6328 - precision: 0.3353 - recall: 0.0860\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.7075 - precision: 0.6124 - recall: 0.4143\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.5133 - accuracy: 0.7390 - precision: 0.6326 - recall: 0.6199\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.5059 - accuracy: 0.7340 - precision: 0.7349 - recall: 0.3777\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.4652 - accuracy: 0.7638 - precision: 0.6651 - recall: 0.6413\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4946 - accuracy: 0.7743 - precision: 0.7556 - recall: 0.5186\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4334 - accuracy: 0.7958 - precision: 0.7032 - recall: 0.6490\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8048 - precision: 0.7281 - recall: 0.6746\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4242 - accuracy: 0.7993 - precision: 0.7534 - recall: 0.6331\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3938 - accuracy: 0.8119 - precision: 0.7149 - recall: 0.7143\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4059 - accuracy: 0.8076 - precision: 0.7309 - recall: 0.6558\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.8033 - precision: 0.7448 - recall: 0.6300\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3876 - accuracy: 0.8146 - precision: 0.7485 - recall: 0.6959\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.8500 - precision: 0.7994 - recall: 0.7302\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3484 - accuracy: 0.8435 - precision: 0.7971 - recall: 0.7473\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3586 - accuracy: 0.8254 - precision: 0.7576 - recall: 0.7499\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3126 - accuracy: 0.8565 - precision: 0.8211 - recall: 0.7123\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.8517 - precision: 0.7833 - recall: 0.7842\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3459 - accuracy: 0.8480 - precision: 0.7590 - recall: 0.8098\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8599 - precision: 0.8079 - recall: 0.7739\n",
      "0.8092105263157895\n",
      "0.6666666666666666\n",
      "0.6635071090047393\n",
      "0.6588235294117646\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3454 - accuracy: 0.8449 - precision: 0.7866 - recall: 0.7172\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2958 - accuracy: 0.8743 - precision: 0.8101 - recall: 0.8009\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2931 - accuracy: 0.8728 - precision: 0.8257 - recall: 0.7715\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2919 - accuracy: 0.8743 - precision: 0.8031 - recall: 0.8122\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2656 - accuracy: 0.8772 - precision: 0.8104 - recall: 0.8122\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2713 - accuracy: 0.8757 - precision: 0.8337 - recall: 0.7715\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2760 - accuracy: 0.8735 - precision: 0.7974 - recall: 0.8190\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2671 - accuracy: 0.8750 - precision: 0.8036 - recall: 0.8145\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2484 - accuracy: 0.8882 - precision: 0.8194 - recall: 0.8416\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2445 - accuracy: 0.8846 - precision: 0.8484 - recall: 0.7851\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2561 - accuracy: 0.8838 - precision: 0.8333 - recall: 0.8032\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.8926 - precision: 0.8575 - recall: 0.8032\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2292 - accuracy: 0.8926 - precision: 0.8458 - recall: 0.8190\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2257 - accuracy: 0.9022 - precision: 0.8552 - recall: 0.8416\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.2147 - accuracy: 0.9081 - precision: 0.8765 - recall: 0.8348\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.2326 - accuracy: 0.8963 - precision: 0.8644 - recall: 0.8077\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2154 - accuracy: 0.9007 - precision: 0.8481 - recall: 0.8462\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1793 - accuracy: 0.9221 - precision: 0.9000 - recall: 0.8552\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1715 - accuracy: 0.9140 - precision: 0.8788 - recall: 0.8529\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1640 - accuracy: 0.9250 - precision: 0.8846 - recall: 0.8846\n",
      "0.8618421052631579\n",
      "0.85\n",
      "0.8415841584158417\n",
      "0.8292682926829269\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1736 - accuracy: 0.9199 - precision: 0.8766 - recall: 0.8862\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.2354 - accuracy: 0.9104 - precision: 0.8764 - recall: 0.8534\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.1927 - accuracy: 0.9052 - precision: 0.8431 - recall: 0.8818\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.1820 - accuracy: 0.9184 - precision: 0.8712 - recall: 0.8884\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1973 - accuracy: 0.9067 - precision: 0.8667 - recall: 0.8534\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1827 - accuracy: 0.9162 - precision: 0.9016 - recall: 0.8425\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1444 - accuracy: 0.9295 - precision: 0.9149 - recall: 0.8709\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1585 - accuracy: 0.9383 - precision: 0.9154 - recall: 0.8993\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1476 - accuracy: 0.9295 - precision: 0.8932 - recall: 0.8972\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.9353 - precision: 0.8985 - recall: 0.9103\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1484 - accuracy: 0.9398 - precision: 0.9032 - recall: 0.9190\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1351 - accuracy: 0.9478 - precision: 0.9142 - recall: 0.9322\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9398 - precision: 0.9121 - recall: 0.9081\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1865 - accuracy: 0.9309 - precision: 0.8937 - recall: 0.9015\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9339 - precision: 0.8963 - recall: 0.9081\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1306 - accuracy: 0.9464 - precision: 0.9305 - recall: 0.9081\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.9515 - precision: 0.9278 - recall: 0.9278\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1100 - accuracy: 0.9522 - precision: 0.9317 - recall: 0.9256\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0956 - accuracy: 0.9655 - precision: 0.9596 - recall: 0.9365\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9302 - precision: 0.9004 - recall: 0.8906\n",
      "0.9470198675496688\n",
      "0.9\n",
      "0.907258064516129\n",
      "0.9183673469387755\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0949 - accuracy: 0.9596 - precision: 0.9478 - recall: 0.9336\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.9566 - precision: 0.9454 - recall: 0.9272\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1519 - accuracy: 0.9368 - precision: 0.9114 - recall: 0.9036\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.9456 - precision: 0.9208 - recall: 0.9208\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.9456 - precision: 0.9190 - recall: 0.9229\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1260 - accuracy: 0.9544 - precision: 0.9318 - recall: 0.9358\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1034 - accuracy: 0.9640 - precision: 0.9391 - recall: 0.9572\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9581 - precision: 0.9343 - recall: 0.9443\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0993 - accuracy: 0.9566 - precision: 0.9322 - recall: 0.9422\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1126 - accuracy: 0.9537 - precision: 0.9280 - recall: 0.9379\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.9640 - precision: 0.9524 - recall: 0.9422\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9750 - precision: 0.9577 - recall: 0.9700\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9831 - precision: 0.9784 - recall: 0.9722\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9780 - precision: 0.9659 - recall: 0.9700\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0964 - accuracy: 0.9640 - precision: 0.9485 - recall: 0.9465\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1135 - accuracy: 0.9566 - precision: 0.9286 - recall: 0.9465\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 0.9713 - precision: 0.9553 - recall: 0.9615\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9772 - precision: 0.9678 - recall: 0.9657\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9750 - precision: 0.9577 - recall: 0.9700\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0979 - accuracy: 0.9669 - precision: 0.9607 - recall: 0.9422\n",
      "0.9867549668874173\n",
      "0.95\n",
      "0.9595959595959596\n",
      "0.9743589743589743\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0615 - accuracy: 0.9721 - precision: 0.9552 - recall: 0.9595\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 0.9772 - precision: 0.9579 - recall: 0.9730\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9765 - precision: 0.9661 - recall: 0.9617\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9625 - precision: 0.9357 - recall: 0.9505\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0957 - accuracy: 0.9640 - precision: 0.9582 - recall: 0.9302\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9750 - precision: 0.9702 - recall: 0.9527\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9758 - precision: 0.9639 - recall: 0.9617\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9566 - precision: 0.9508 - recall: 0.9144\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0922 - accuracy: 0.9677 - precision: 0.9444 - recall: 0.9572\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 0.9743 - precision: 0.9637 - recall: 0.9572\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0914 - accuracy: 0.9706 - precision: 0.9676 - recall: 0.9414\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0792 - accuracy: 0.9662 - precision: 0.9543 - recall: 0.9414\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0851 - accuracy: 0.9684 - precision: 0.9567 - recall: 0.9459\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1098 - accuracy: 0.9603 - precision: 0.9372 - recall: 0.9414\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.9596 - precision: 0.9391 - recall: 0.9369\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.9758 - precision: 0.9557 - recall: 0.9707\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0910 - accuracy: 0.9706 - precision: 0.9449 - recall: 0.9662\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 0.9794 - precision: 0.9685 - recall: 0.9685\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9838 - precision: 0.9817 - recall: 0.9685\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0532 - accuracy: 0.9780 - precision: 0.9559 - recall: 0.9775\n",
      "0.9735099337748344\n",
      "0.9830508474576272\n",
      "0.9764309764309764\n",
      "0.9666666666666667\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9868 - precision: 0.9846 - recall: 0.9760\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9860 - precision: 0.9741 - recall: 0.9847\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 0.9882 - precision: 0.9847 - recall: 0.9804\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 0.9787 - precision: 0.9715 - recall: 0.9651\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9780 - precision: 0.9673 - recall: 0.9673\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9890 - precision: 0.9847 - recall: 0.9826\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9559 - precision: 0.9290 - recall: 0.9412\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0478 - accuracy: 0.9831 - precision: 0.9658 - recall: 0.9847\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9919 - precision: 0.9870 - recall: 0.9891\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9846 - precision: 0.9824 - recall: 0.9717\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0533 - accuracy: 0.9809 - precision: 0.9676 - recall: 0.9760\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9853 - precision: 0.9761 - recall: 0.9804\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9816 - precision: 0.9697 - recall: 0.9760\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9802 - precision: 0.9675 - recall: 0.9739\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.9566 - precision: 0.9348 - recall: 0.9368\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0569 - accuracy: 0.9816 - precision: 0.9637 - recall: 0.9826\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1185 - accuracy: 0.9669 - precision: 0.9461 - recall: 0.9564\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0783 - accuracy: 0.9780 - precision: 0.9653 - recall: 0.9695\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0671 - accuracy: 0.9780 - precision: 0.9756 - recall: 0.9586\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9787 - precision: 0.9634 - recall: 0.9739\n",
      "0.9801324503311258\n",
      "0.9574468085106383\n",
      "0.9615384615384617\n",
      "0.967741935483871\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9846 - precision: 0.9761 - recall: 0.9783\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.9824 - precision: 0.9781 - recall: 0.9696\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9897 - precision: 0.9890 - recall: 0.9804\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0556 - accuracy: 0.9846 - precision: 0.9761 - recall: 0.9783\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9868 - precision: 0.9784 - recall: 0.9826\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9919 - precision: 0.9978 - recall: 0.9783\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9919 - precision: 0.9891 - recall: 0.9870\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9891\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9904 - precision: 0.9869 - recall: 0.9848\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9956 - precision: 0.9935 - recall: 0.9935\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9934 - precision: 0.9892 - recall: 0.9913\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9949 - precision: 0.9978 - recall: 0.9870\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9963 - precision: 0.9956 - recall: 0.9935\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - precision: 0.9978 - recall: 0.9978\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1617 - accuracy: 0.9530 - precision: 0.9381 - recall: 0.9217\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.9442 - precision: 0.9528 - recall: 0.8783\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9809 - precision: 0.9801 - recall: 0.9630\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0689 - accuracy: 0.9860 - precision: 0.9783 - recall: 0.9804\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0753 - accuracy: 0.9728 - precision: 0.9628 - recall: 0.9565\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.9860 - precision: 0.9804 - recall: 0.9783\n",
      "0.9867549668874173\n",
      "0.9777777777777777\n",
      "0.9777777777777777\n",
      "0.9777777777777777\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9787 - precision: 0.9643 - recall: 0.9708\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9838 - precision: 0.9753 - recall: 0.9753\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9904 - precision: 0.9821 - recall: 0.9888\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9934 - precision: 0.9910 - recall: 0.9888\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.9728 - precision: 0.9679 - recall: 0.9483\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0879 - accuracy: 0.9706 - precision: 0.9655 - recall: 0.9438\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0548 - accuracy: 0.9816 - precision: 0.9839 - recall: 0.9596\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9897 - precision: 0.9865 - recall: 0.9820\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9860 - precision: 0.9819 - recall: 0.9753\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0620 - accuracy: 0.9846 - precision: 0.9775 - recall: 0.9753\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9919 - precision: 0.9865 - recall: 0.9888\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9934 - precision: 0.9955 - recall: 0.9843\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 0.9853 - precision: 0.9733 - recall: 0.9820\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9985 - precision: 0.9978 - recall: 0.9978\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9949 - precision: 0.9888 - recall: 0.9955\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9802 - precision: 0.9644 - recall: 0.9753\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9882 - precision: 0.9694 - recall: 0.9955\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9978\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9875 - precision: 0.9735 - recall: 0.9888\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9890 - precision: 0.9799 - recall: 0.9865\n",
      "0.9801324503311258\n",
      "0.9523809523809523\n",
      "0.9615384615384615\n",
      "0.975609756097561\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0483 - accuracy: 0.9882 - precision: 0.9737 - recall: 0.9911\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9912 - precision: 0.9823 - recall: 0.9911\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.9890 - precision: 0.9822 - recall: 0.9844\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9860 - precision: 0.9757 - recall: 0.9822\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 0.9868 - precision: 0.9800 - recall: 0.9800\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9934 - precision: 0.9846 - recall: 0.9955\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 0.9941 - precision: 0.9889 - recall: 0.9933\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9721 - precision: 0.9419 - recall: 0.9755\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9780 - precision: 0.9525 - recall: 0.9822\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0525 - accuracy: 0.9838 - precision: 0.9672 - recall: 0.9844\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0648 - accuracy: 0.9838 - precision: 0.9713 - recall: 0.9800\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9919 - precision: 0.9867 - recall: 0.9889\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 0.9949 - precision: 0.9933 - recall: 0.9911\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9927 - precision: 0.9933 - recall: 0.9844\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9949 - precision: 0.9933 - recall: 0.9911\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 0.9978 - precision: 0.9956 - recall: 0.9978\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9963 - precision: 0.9933 - recall: 0.9955\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 0.9985 - precision: 1.0000 - recall: 0.9955\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.9985 - precision: 0.9978 - recall: 0.9978\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.9985 - precision: 0.9978 - recall: 0.9978\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9919 - precision: 0.9891 - recall: 0.9870\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8773 - precision: 0.8415 - recall: 0.7848\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1013 - accuracy: 0.9655 - precision: 0.9479 - recall: 0.9500\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9735 - precision: 0.9690 - recall: 0.9522\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9882 - precision: 0.9890 - recall: 0.9761\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9802 - precision: 0.9758 - recall: 0.9652\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9794 - precision: 0.9779 - recall: 0.9609\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9941 - precision: 0.9956 - recall: 0.9870\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9919 - precision: 0.9912 - recall: 0.9848\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9882 - precision: 0.9784 - recall: 0.9870\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9816 - precision: 0.9718 - recall: 0.9739\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9912 - precision: 0.9891 - recall: 0.9848\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9927 - precision: 0.9891 - recall: 0.9891\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9949 - precision: 0.9913 - recall: 0.9935\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9846 - precision: 0.9803 - recall: 0.9739\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9824 - precision: 0.9678 - recall: 0.9804\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9853 - precision: 0.9783 - recall: 0.9783\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9882 - precision: 0.9805 - recall: 0.9848\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9904 - precision: 0.9891 - recall: 0.9826\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9891\n",
      "0.9933774834437086\n",
      "0.9782608695652174\n",
      "0.982532751091703\n",
      "0.989010989010989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "\n",
    "n_split=10\n",
    "\n",
    "for train_index,test_index in KFold(n_split).split(X_train):\n",
    "  x_train,x_test=X[train_index],X[test_index]\n",
    "  y_train,y_test=y[train_index],y[test_index]\n",
    "\n",
    "  sc = StandardScaler()\n",
    "  x_train = sc.fit_transform(x_train)\n",
    "  x_test = sc.transform(x_test)\n",
    "  \n",
    "  \n",
    "  ann.fit(x_train, y_train, epochs=20)\n",
    "  y_pred = ann.predict(x_test)\n",
    "  y_pred = np.array([0  if i<0.5 else 1 for i in y_pred])\n",
    "\n",
    "  # ann.evaluate(x_test, y_test)\n",
    "\n",
    "  print(accuracy_score(y_test,y_pred))\n",
    "  print(precision_score(y_test, y_pred))\n",
    "  print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "  print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.fit(X_train, y_train, batch_size=32, epochs=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = ann.predict(X_test)\n",
    "Y_pred = np.array([0  if i<0.5 else 1 for i in Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255,   0],\n",
       "       [  1, 122]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973544973544973\n",
      "1.0\n",
      "0.9983633387888707\n",
      "0.9959183673469388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(precision_score(Y_test, Y_pred))\n",
    "print(fbeta_score(Y_test, Y_pred, beta=0.5))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.976\n",
    "\n",
    "0.945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "# print(accuracy_score(y_test,y_pred))\n",
    "# print(precision_score(y_test, y_pred))\n",
    "# print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "# print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.973\n",
    "\n",
    "0.952\n",
    "\n",
    "0.955\n",
    "\n",
    "0.959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.save('models/annModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "preds = Y_pred\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(Y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.99186992, 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.9959266633137136, 0.0]\n",
      "Best Threshold=1.000000, G-Mean=0.996\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "gmeans = []\n",
    "for iq in range(len(tpr)):\n",
    "   gmeans.append(math.sqrt(np.array(tpr[iq]) * (1-np.array(fpr[iq]))))\n",
    "print(gmeans)\n",
    "\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (threshold[ix], gmeans[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 is the optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
