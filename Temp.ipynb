{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PIMA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2      138             62             35        0  33.6   \n",
       "1               0       84             82             31      125  38.2   \n",
       "2               0      145              0              0        0  44.2   \n",
       "3               0      135             68             42      250  42.3   \n",
       "4               1      139             62             41      480  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2       75             64             24       55  29.7   \n",
       "1996            8      179             72             42      130  32.7   \n",
       "1997            6       85             78              0        0  31.2   \n",
       "1998            0      129            110             46      130  67.1   \n",
       "1999            2       81             72             15       76  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.703500</td>\n",
       "      <td>121.182500</td>\n",
       "      <td>69.145500</td>\n",
       "      <td>20.935000</td>\n",
       "      <td>80.254000</td>\n",
       "      <td>32.193000</td>\n",
       "      <td>0.470930</td>\n",
       "      <td>33.090500</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.306063</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>0.474498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies      Glucose  BloodPressure  SkinThickness      Insulin  \\\n",
       "count  2000.000000  2000.000000    2000.000000    2000.000000  2000.000000   \n",
       "mean      3.703500   121.182500      69.145500      20.935000    80.254000   \n",
       "std       3.306063    32.068636      19.188315      16.103243   111.180534   \n",
       "min       0.000000     0.000000       0.000000       0.000000     0.000000   \n",
       "25%       1.000000    99.000000      63.500000       0.000000     0.000000   \n",
       "50%       3.000000   117.000000      72.000000      23.000000    40.000000   \n",
       "75%       6.000000   141.000000      80.000000      32.000000   130.000000   \n",
       "max      17.000000   199.000000     122.000000     110.000000   744.000000   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction          Age      Outcome  \n",
       "count  2000.000000               2000.000000  2000.000000  2000.000000  \n",
       "mean     32.193000                  0.470930    33.090500     0.342000  \n",
       "std       8.149901                  0.323553    11.786423     0.474498  \n",
       "min       0.000000                  0.078000    21.000000     0.000000  \n",
       "25%      27.375000                  0.244000    24.000000     0.000000  \n",
       "50%      32.300000                  0.376000    29.000000     0.000000  \n",
       "75%      36.800000                  0.624000    40.000000     1.000000  \n",
       "max      80.600000                  2.420000    81.000000     1.000000  "
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['DiabetesPedigreeFunction'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Pregnancies    2000 non-null   int64  \n",
      " 1   Glucose        2000 non-null   int64  \n",
      " 2   BloodPressure  2000 non-null   int64  \n",
      " 3   SkinThickness  2000 non-null   int64  \n",
      " 4   Insulin        2000 non-null   int64  \n",
      " 5   BMI            2000 non-null   float64\n",
      " 6   Age            2000 non-null   int64  \n",
      " 7   Outcome        2000 non-null   int64  \n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11766/684818280.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
      "/tmp/ipykernel_11766/684818280.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan\n"
     ]
    }
   ],
   "source": [
    "df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
    "df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32</td>\n",
       "      <td>265</td>\n",
       "      <td>46.5</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1890 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  Age  \\\n",
       "0               2    138.0           62.0             35        0  33.6   47   \n",
       "1               0     84.0           82.0             31      125  38.2   23   \n",
       "3               0    135.0           68.0             42      250  42.3   24   \n",
       "4               1    139.0           62.0             41      480  40.7   21   \n",
       "5               0    173.0           78.0             32      265  46.5   58   \n",
       "...           ...      ...            ...            ...      ...   ...  ...   \n",
       "1995            2     75.0           64.0             24       55  29.7   33   \n",
       "1996            8    179.0           72.0             42      130  32.7   36   \n",
       "1997            6     85.0           78.0              0        0  31.2   42   \n",
       "1998            0    129.0          110.0             46      130  67.1   26   \n",
       "1999            2     81.0           72.0             15       76  30.1   25   \n",
       "\n",
       "      Outcome  \n",
       "0           1  \n",
       "1           0  \n",
       "3           1  \n",
       "4           0  \n",
       "5           0  \n",
       "...       ...  \n",
       "1995        0  \n",
       "1996        1  \n",
       "1997        0  \n",
       "1998        1  \n",
       "1999        0  \n",
       "\n",
       "[1890 rows x 8 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2. , 138. ,  62. , ...,   0. ,  33.6,  47. ],\n",
       "       [  0. ,  84. ,  82. , ..., 125. ,  38.2,  23. ],\n",
       "       [  0. , 135. ,  68. , ..., 250. ,  42.3,  24. ],\n",
       "       ...,\n",
       "       [  6. ,  85. ,  78. , ...,   0. ,  31.2,  42. ],\n",
       "       [  0. , 129. , 110. , ..., 130. ,  67.1,  26. ],\n",
       "       [  2. ,  81. ,  72. , ...,  76. ,  30.1,  25. ]])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "model_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=131, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=274, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=479, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=389, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=59, activation='relu'))\n",
    "model_ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_ann.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall')\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7378 - precision: 0.6182 - recall: 0.4936 \n",
      "Epoch 2/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7808 - precision: 0.6725 - recall: 0.6746\n",
      "Epoch 3/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8034 - precision: 0.7018 - recall: 0.6902\n",
      "Epoch 4/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8113 - precision: 0.7032 - recall: 0.7867\n",
      "Epoch 5/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8260 - precision: 0.7169 - recall: 0.7604\n",
      "Epoch 6/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8426 - precision: 0.7614 - recall: 0.7805\n",
      "Epoch 7/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.3088 - accuracy: 0.8571 - precision: 0.7550 - recall: 0.8323\n",
      "Epoch 8/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.8736 - precision: 0.8146 - recall: 0.8259\n",
      "Epoch 9/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8901 - precision: 0.8280 - recall: 0.8334\n",
      "Epoch 10/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.8801 - precision: 0.8175 - recall: 0.8434\n",
      "Epoch 11/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9161 - precision: 0.8795 - recall: 0.8683\n",
      "Epoch 12/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9212 - precision: 0.8937 - recall: 0.8753\n",
      "Epoch 13/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1421 - accuracy: 0.9517 - precision: 0.9349 - recall: 0.9257\n",
      "Epoch 14/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.9339 - precision: 0.9276 - recall: 0.8900\n",
      "Epoch 15/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1244 - accuracy: 0.9544 - precision: 0.9266 - recall: 0.9463\n",
      "Epoch 16/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9297 - precision: 0.9041 - recall: 0.8903\n",
      "Epoch 17/300\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.9515 - precision: 0.9175 - recall: 0.9336\n",
      "Epoch 18/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9814 - precision: 0.9783 - recall: 0.9651\n",
      "Epoch 19/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9642 - precision: 0.9666 - recall: 0.9290\n",
      "Epoch 20/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9739 - precision: 0.9739 - recall: 0.9467\n",
      "Epoch 21/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9864 - precision: 0.9775 - recall: 0.9828\n",
      "Epoch 22/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9893 - precision: 0.9836 - recall: 0.9844\n",
      "Epoch 23/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9891 - precision: 0.9818 - recall: 0.9876\n",
      "Epoch 24/300\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.0447 - accuracy: 0.9846 - precision: 0.9790 - recall: 0.9761\n",
      "Epoch 25/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9664 - precision: 0.9416 - recall: 0.9650\n",
      "Epoch 26/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9872 - precision: 0.9930 - recall: 0.9693\n",
      "Epoch 27/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9909 - precision: 0.9971 - recall: 0.9754\n",
      "Epoch 28/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9957 - precision: 0.9912 - recall: 0.9970\n",
      "Epoch 29/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9973 - precision: 0.9922 - recall: 0.9992\n",
      "Epoch 30/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9983 - precision: 0.9950 - recall: 1.0000\n",
      "Epoch 31/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.5220e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4.0166e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2947e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.8749e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.5011e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.2397e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.0096e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.3943e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8131e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 5.1136e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 3.3361e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.4879e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9171e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9159e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 46/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2416e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.4440e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0331e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 49/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.3750e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 5.8707e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.8277e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 52/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.2844e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.6033e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.5459e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.3855e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 56/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.2887e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4.4075e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.2042e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7051e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.3719e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.4040e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.7946e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.6854e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.7518e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 65/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.5969e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 66/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1791e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 67/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.3031e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.5014e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4598e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 70/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4925e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 71/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4487e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 72/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.9115e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 73/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1014e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000A: 0s - loss: 7.9832e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1\n",
      "Epoch 74/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0898e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 75/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.0862e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 76/300\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 9.5624e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 77/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.1629e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 78/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.5910e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 79/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.7089e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 80/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 6.7684e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 81/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.1942e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 82/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 6.3928e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 83/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.3541e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 84/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4.8910e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 85/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7805e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 86/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.5064e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 87/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.6912e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 88/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7718e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 89/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.8637e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 90/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.8399e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.4307e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 92/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.1744e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 93/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.8685e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 94/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.9434e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 95/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2373e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 96/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.8152e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 97/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.3269e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 98/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.5895e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 99/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 3.6604e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 100/300\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 3.0681e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 101/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.7058e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 102/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.8850e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 103/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.4160e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 104/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.5680e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 105/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.7791e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 106/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.4285e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 107/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.5938e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 108/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.5967e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 109/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9343e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 110/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0663e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 111/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.3642e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 112/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.0053e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 113/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.7334e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 114/300\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.7393e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 115/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.7902e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 116/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6885e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 117/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6892e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 118/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8002e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 119/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4371e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 120/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2145e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 121/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4671e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 122/300\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.2581e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 123/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1638e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 124/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4419e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 125/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.7563e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 126/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3566e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 127/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.1347e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 128/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0315e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 129/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 130/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.2576e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 131/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0906e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 132/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2552e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 133/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1415e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 134/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.3585e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 135/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1576e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 136/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.5829e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 137/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0482e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 138/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.1190e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 139/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.8697e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 140/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.8458e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 141/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4569e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 142/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.7279e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 143/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 7.4888e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 144/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3155e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 145/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2821e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 146/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.1042e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 147/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.6724e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 148/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4465e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 149/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2081e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 150/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3260e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 151/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7968e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 152/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2323e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 153/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4140e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 154/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8653e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 155/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.2412e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 156/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6168e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 157/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1323e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 158/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8492e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 159/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.2074e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 160/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.5703e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 161/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0783e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 162/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.1403e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 163/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7086e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 164/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.1965e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 165/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.4073e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 166/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.7067e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 167/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9702e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 168/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.9963e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 169/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.2421e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 170/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.0474e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 171/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.7309e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 172/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.3577e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 173/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.3229e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 174/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6608e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 175/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.1238e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 176/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.4439e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 177/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.1171e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 178/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2161e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 179/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.5087e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 180/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.0168e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 181/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.1825e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 182/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6854e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 183/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.8295e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 184/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.5387e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 185/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6362e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 186/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.8146e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 187/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9044e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 188/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3011e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 189/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2014e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 190/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9361e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 191/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9272e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 192/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9864e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 193/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2011e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 194/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.4997e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 195/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6927e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 196/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6388e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 197/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0694e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 198/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8823e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 199/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.7473e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 200/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6686e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 201/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9332e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 202/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6013e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 203/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8226e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 204/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6950e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 205/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.5706e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 206/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.8123e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 207/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.7980e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 208/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4683e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 209/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4529e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 210/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.3950e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 211/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0557e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 212/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2347e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 213/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3097e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 214/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.6992e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 215/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1669e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 216/300\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4785e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 217/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.3069e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 218/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.8850e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 219/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2107e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 220/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.4447e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 221/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.8799e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 222/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1911e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 223/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0936e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 224/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2492e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 225/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.9758e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 226/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 9.8632e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 227/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.9225e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 228/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2238e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 229/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 9.5343e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 230/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.8643e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 231/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1242e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 232/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0590e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 233/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.7641e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 234/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 9.4023e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 235/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.0316e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 236/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.7654e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 237/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.5985e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 238/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0167e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 239/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.5809e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 240/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.8024e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 241/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.4208e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 242/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.2025e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 243/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 6.6051e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 244/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.1467e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 245/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.1178e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 246/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.3455e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 247/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.0912e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 248/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.5249e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 249/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.9133e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 250/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.4710e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 251/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.6871e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 252/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.8393e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 253/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.0337e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 254/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.5793e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 255/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.2927e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 256/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.1561e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 257/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9466e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 258/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.0910e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 259/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.9863e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 260/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.4183e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 261/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.6359e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 262/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9803e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 263/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.3532e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 264/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.4525e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 265/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.6192e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 266/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.2314e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 267/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9084e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 268/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.4189e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 269/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9530e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 270/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.1695e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 271/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.4681e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 272/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7296e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 273/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.5089e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 274/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8872e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 275/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.5653e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 276/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2806e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 277/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.7275e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 278/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2143e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 279/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2366e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 280/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.2749e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 281/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.5345e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 282/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.6463e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 283/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.6638e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 284/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.3477e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 285/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.4228e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 286/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.6381e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 287/300\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 3.2403e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 288/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.4272e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 289/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.3087e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 290/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.1644e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 291/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.6815e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 292/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.9025e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 293/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.8563e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 294/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.3242e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 295/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.7921e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 296/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.8275e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 297/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.3464e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 298/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.3050e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 299/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.0624e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 300/300\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3.1235e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f790f39cee0>"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ann.fit(X_train, y_train, batch_size=32, epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5850059\ttotal: 1.61ms\tremaining: 14.5ms\n",
      "1:\tlearn: 0.5293254\ttotal: 4.31ms\tremaining: 17.2ms\n",
      "2:\tlearn: 0.4930310\ttotal: 5.99ms\tremaining: 14ms\n",
      "3:\tlearn: 0.4599207\ttotal: 7.9ms\tremaining: 11.8ms\n",
      "4:\tlearn: 0.4370265\ttotal: 9.46ms\tremaining: 9.46ms\n",
      "5:\tlearn: 0.4163258\ttotal: 10.9ms\tremaining: 7.27ms\n",
      "6:\tlearn: 0.4039125\ttotal: 12.4ms\tremaining: 5.3ms\n",
      "7:\tlearn: 0.3911796\ttotal: 13.8ms\tremaining: 3.44ms\n",
      "8:\tlearn: 0.3810411\ttotal: 15.2ms\tremaining: 1.68ms\n",
      "9:\tlearn: 0.3724581\ttotal: 16.6ms\tremaining: 0us\n",
      "0:\tlearn: 0.5905896\ttotal: 1.45ms\tremaining: 13ms\n",
      "1:\tlearn: 0.5366589\ttotal: 3.02ms\tremaining: 12.1ms\n",
      "2:\tlearn: 0.4996551\ttotal: 4.57ms\tremaining: 10.7ms\n",
      "3:\tlearn: 0.4666418\ttotal: 6.4ms\tremaining: 9.61ms\n",
      "4:\tlearn: 0.4453798\ttotal: 9.47ms\tremaining: 9.47ms\n",
      "5:\tlearn: 0.4230393\ttotal: 11.2ms\tremaining: 7.47ms\n",
      "6:\tlearn: 0.4084736\ttotal: 12.7ms\tremaining: 5.45ms\n",
      "7:\tlearn: 0.3974617\ttotal: 16.1ms\tremaining: 4.03ms\n",
      "8:\tlearn: 0.3884616\ttotal: 17.8ms\tremaining: 1.98ms\n",
      "9:\tlearn: 0.3755488\ttotal: 19.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.5977418\ttotal: 1.61ms\tremaining: 14.5ms\n",
      "1:\tlearn: 0.5428161\ttotal: 3.19ms\tremaining: 12.8ms\n",
      "2:\tlearn: 0.5009722\ttotal: 4.6ms\tremaining: 10.7ms\n",
      "3:\tlearn: 0.4618783\ttotal: 5.94ms\tremaining: 8.91ms\n",
      "4:\tlearn: 0.4382324\ttotal: 7.26ms\tremaining: 7.26ms\n",
      "5:\tlearn: 0.4176624\ttotal: 8.76ms\tremaining: 5.84ms\n",
      "6:\tlearn: 0.4047141\ttotal: 10.1ms\tremaining: 4.32ms\n",
      "7:\tlearn: 0.3916092\ttotal: 12.7ms\tremaining: 3.19ms\n",
      "8:\tlearn: 0.3807510\ttotal: 15.1ms\tremaining: 1.68ms\n",
      "9:\tlearn: 0.3705390\ttotal: 16.6ms\tremaining: 0us\n",
      "0:\tlearn: 0.5869797\ttotal: 1.46ms\tremaining: 13.1ms\n",
      "1:\tlearn: 0.5323438\ttotal: 2.94ms\tremaining: 11.7ms\n",
      "2:\tlearn: 0.4987412\ttotal: 4.44ms\tremaining: 10.4ms\n",
      "3:\tlearn: 0.4644054\ttotal: 6.03ms\tremaining: 9.05ms\n",
      "4:\tlearn: 0.4438078\ttotal: 7.35ms\tremaining: 7.35ms\n",
      "5:\tlearn: 0.4235212\ttotal: 8.99ms\tremaining: 6ms\n",
      "6:\tlearn: 0.4134371\ttotal: 10.3ms\tremaining: 4.43ms\n",
      "7:\tlearn: 0.4003662\ttotal: 12ms\tremaining: 3.01ms\n",
      "8:\tlearn: 0.3913037\ttotal: 13.5ms\tremaining: 1.5ms\n",
      "9:\tlearn: 0.3827279\ttotal: 14.9ms\tremaining: 0us\n",
      "0:\tlearn: 0.5957690\ttotal: 1.32ms\tremaining: 11.9ms\n",
      "1:\tlearn: 0.5391555\ttotal: 2.7ms\tremaining: 10.8ms\n",
      "2:\tlearn: 0.4944143\ttotal: 4.08ms\tremaining: 9.52ms\n",
      "3:\tlearn: 0.4617213\ttotal: 5.5ms\tremaining: 8.25ms\n",
      "4:\tlearn: 0.4379657\ttotal: 7.16ms\tremaining: 7.16ms\n",
      "5:\tlearn: 0.4148065\ttotal: 9.06ms\tremaining: 6.04ms\n",
      "6:\tlearn: 0.4006933\ttotal: 11.2ms\tremaining: 4.8ms\n",
      "7:\tlearn: 0.3873215\ttotal: 13.4ms\tremaining: 3.34ms\n",
      "8:\tlearn: 0.3723908\ttotal: 15.1ms\tremaining: 1.67ms\n",
      "9:\tlearn: 0.3609135\ttotal: 16.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.5850059\ttotal: 1.39ms\tremaining: 19.4ms\n",
      "1:\tlearn: 0.5293254\ttotal: 3.26ms\tremaining: 21.2ms\n",
      "2:\tlearn: 0.4930310\ttotal: 4.69ms\tremaining: 18.8ms\n",
      "3:\tlearn: 0.4599207\ttotal: 6.62ms\tremaining: 18.2ms\n",
      "4:\tlearn: 0.4370265\ttotal: 8.1ms\tremaining: 16.2ms\n",
      "5:\tlearn: 0.4163258\ttotal: 9.52ms\tremaining: 14.3ms\n",
      "6:\tlearn: 0.4039125\ttotal: 10.9ms\tremaining: 12.5ms\n",
      "7:\tlearn: 0.3911796\ttotal: 12.3ms\tremaining: 10.7ms\n",
      "8:\tlearn: 0.3810411\ttotal: 14ms\tremaining: 9.36ms\n",
      "9:\tlearn: 0.3724581\ttotal: 15.5ms\tremaining: 7.77ms\n",
      "10:\tlearn: 0.3624031\ttotal: 17.3ms\tremaining: 6.29ms\n",
      "11:\tlearn: 0.3563331\ttotal: 18.8ms\tremaining: 4.7ms\n",
      "12:\tlearn: 0.3496682\ttotal: 20.3ms\tremaining: 3.12ms\n",
      "13:\tlearn: 0.3430955\ttotal: 21.7ms\tremaining: 1.55ms\n",
      "14:\tlearn: 0.3364904\ttotal: 23.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.5905896\ttotal: 1.39ms\tremaining: 19.4ms\n",
      "1:\tlearn: 0.5366589\ttotal: 12ms\tremaining: 77.8ms\n",
      "2:\tlearn: 0.4996551\ttotal: 13.6ms\tremaining: 54.5ms\n",
      "3:\tlearn: 0.4666418\ttotal: 16.4ms\tremaining: 45ms\n",
      "4:\tlearn: 0.4453798\ttotal: 17.8ms\tremaining: 35.5ms\n",
      "5:\tlearn: 0.4230393\ttotal: 19.2ms\tremaining: 28.8ms\n",
      "6:\tlearn: 0.4084736\ttotal: 23.7ms\tremaining: 27ms\n",
      "7:\tlearn: 0.3974617\ttotal: 25.3ms\tremaining: 22.1ms\n",
      "8:\tlearn: 0.3884616\ttotal: 26.8ms\tremaining: 17.9ms\n",
      "9:\tlearn: 0.3755488\ttotal: 28.4ms\tremaining: 14.2ms\n",
      "10:\tlearn: 0.3689409\ttotal: 29.8ms\tremaining: 10.8ms\n",
      "11:\tlearn: 0.3649023\ttotal: 31.2ms\tremaining: 7.81ms\n",
      "12:\tlearn: 0.3579666\ttotal: 32.6ms\tremaining: 5.02ms\n",
      "13:\tlearn: 0.3479412\ttotal: 34ms\tremaining: 2.43ms\n",
      "14:\tlearn: 0.3436222\ttotal: 35.6ms\tremaining: 0us\n",
      "0:\tlearn: 0.5977418\ttotal: 1.3ms\tremaining: 18.3ms\n",
      "1:\tlearn: 0.5428161\ttotal: 2.92ms\tremaining: 19ms\n",
      "2:\tlearn: 0.5009722\ttotal: 4.36ms\tremaining: 17.4ms\n",
      "3:\tlearn: 0.4618783\ttotal: 5.65ms\tremaining: 15.6ms\n",
      "4:\tlearn: 0.4382324\ttotal: 6.88ms\tremaining: 13.8ms\n",
      "5:\tlearn: 0.4176624\ttotal: 7.97ms\tremaining: 12ms\n",
      "6:\tlearn: 0.4047141\ttotal: 9.14ms\tremaining: 10.5ms\n",
      "7:\tlearn: 0.3916092\ttotal: 10.3ms\tremaining: 9.05ms\n",
      "8:\tlearn: 0.3807510\ttotal: 11.5ms\tremaining: 7.66ms\n",
      "9:\tlearn: 0.3705390\ttotal: 13.4ms\tremaining: 6.68ms\n",
      "10:\tlearn: 0.3620510\ttotal: 14.6ms\tremaining: 5.31ms\n",
      "11:\tlearn: 0.3537308\ttotal: 16ms\tremaining: 4ms\n",
      "12:\tlearn: 0.3464841\ttotal: 17.3ms\tremaining: 2.67ms\n",
      "13:\tlearn: 0.3371682\ttotal: 18.5ms\tremaining: 1.32ms\n",
      "14:\tlearn: 0.3302017\ttotal: 19.7ms\tremaining: 0us\n",
      "0:\tlearn: 0.5869797\ttotal: 1.24ms\tremaining: 17.4ms\n",
      "1:\tlearn: 0.5323438\ttotal: 2.35ms\tremaining: 15.3ms\n",
      "2:\tlearn: 0.4987412\ttotal: 3.55ms\tremaining: 14.2ms\n",
      "3:\tlearn: 0.4644054\ttotal: 4.73ms\tremaining: 13ms\n",
      "4:\tlearn: 0.4438078\ttotal: 5.9ms\tremaining: 11.8ms\n",
      "5:\tlearn: 0.4235212\ttotal: 7.12ms\tremaining: 10.7ms\n",
      "6:\tlearn: 0.4134371\ttotal: 9.6ms\tremaining: 11ms\n",
      "7:\tlearn: 0.4003662\ttotal: 10.7ms\tremaining: 9.4ms\n",
      "8:\tlearn: 0.3913037\ttotal: 11.9ms\tremaining: 7.92ms\n",
      "9:\tlearn: 0.3827279\ttotal: 12.9ms\tremaining: 6.43ms\n",
      "10:\tlearn: 0.3773587\ttotal: 14.1ms\tremaining: 5.13ms\n",
      "11:\tlearn: 0.3732694\ttotal: 15.3ms\tremaining: 3.82ms\n",
      "12:\tlearn: 0.3662998\ttotal: 16.4ms\tremaining: 2.52ms\n",
      "13:\tlearn: 0.3539885\ttotal: 17.6ms\tremaining: 1.26ms\n",
      "14:\tlearn: 0.3454823\ttotal: 18.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.5957690\ttotal: 1.2ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.5391555\ttotal: 2.48ms\tremaining: 16.1ms\n",
      "2:\tlearn: 0.4944143\ttotal: 3.57ms\tremaining: 14.3ms\n",
      "3:\tlearn: 0.4617213\ttotal: 4.7ms\tremaining: 12.9ms\n",
      "4:\tlearn: 0.4379657\ttotal: 7.67ms\tremaining: 15.3ms\n",
      "5:\tlearn: 0.4148065\ttotal: 9.02ms\tremaining: 13.5ms\n",
      "6:\tlearn: 0.4006933\ttotal: 10.2ms\tremaining: 11.7ms\n",
      "7:\tlearn: 0.3873215\ttotal: 11.4ms\tremaining: 9.98ms\n",
      "8:\tlearn: 0.3723908\ttotal: 12.6ms\tremaining: 8.41ms\n",
      "9:\tlearn: 0.3609135\ttotal: 13.8ms\tremaining: 6.9ms\n",
      "10:\tlearn: 0.3530555\ttotal: 14.9ms\tremaining: 5.43ms\n",
      "11:\tlearn: 0.3417236\ttotal: 16.1ms\tremaining: 4.02ms\n",
      "12:\tlearn: 0.3361178\ttotal: 17.2ms\tremaining: 2.65ms\n",
      "13:\tlearn: 0.3294009\ttotal: 18.4ms\tremaining: 1.31ms\n",
      "14:\tlearn: 0.3235653\ttotal: 19.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6564798\ttotal: 1.22ms\tremaining: 23.2ms\n",
      "1:\tlearn: 0.6304403\ttotal: 2.58ms\tremaining: 23.3ms\n",
      "2:\tlearn: 0.6084884\ttotal: 3.84ms\tremaining: 21.7ms\n",
      "3:\tlearn: 0.5895111\ttotal: 7.48ms\tremaining: 29.9ms\n",
      "4:\tlearn: 0.5694251\ttotal: 8.86ms\tremaining: 26.6ms\n",
      "5:\tlearn: 0.5503846\ttotal: 10.1ms\tremaining: 23.5ms\n",
      "6:\tlearn: 0.5363235\ttotal: 11.3ms\tremaining: 21.1ms\n",
      "7:\tlearn: 0.5212106\ttotal: 12.6ms\tremaining: 18.9ms\n",
      "8:\tlearn: 0.5076310\ttotal: 13.8ms\tremaining: 16.8ms\n",
      "9:\tlearn: 0.4957357\ttotal: 15ms\tremaining: 15ms\n",
      "10:\tlearn: 0.4848768\ttotal: 16.3ms\tremaining: 13.3ms\n",
      "11:\tlearn: 0.4757247\ttotal: 17.5ms\tremaining: 11.7ms\n",
      "12:\tlearn: 0.4660490\ttotal: 18.7ms\tremaining: 10.1ms\n",
      "13:\tlearn: 0.4562197\ttotal: 20.5ms\tremaining: 8.76ms\n",
      "14:\tlearn: 0.4478630\ttotal: 22.1ms\tremaining: 7.38ms\n",
      "15:\tlearn: 0.4412983\ttotal: 23.6ms\tremaining: 5.91ms\n",
      "16:\tlearn: 0.4348896\ttotal: 24.9ms\tremaining: 4.39ms\n",
      "17:\tlearn: 0.4273419\ttotal: 26.1ms\tremaining: 2.9ms\n",
      "18:\tlearn: 0.4207556\ttotal: 27.4ms\tremaining: 1.44ms\n",
      "19:\tlearn: 0.4149928\ttotal: 28.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6584466\ttotal: 1.33ms\tremaining: 25.3ms\n",
      "1:\tlearn: 0.6326510\ttotal: 2.81ms\tremaining: 25.3ms\n",
      "2:\tlearn: 0.6107639\ttotal: 4.14ms\tremaining: 23.5ms\n",
      "3:\tlearn: 0.5903611\ttotal: 5.49ms\tremaining: 22ms\n",
      "4:\tlearn: 0.5731909\ttotal: 7.73ms\tremaining: 23.2ms\n",
      "5:\tlearn: 0.5551403\ttotal: 9.4ms\tremaining: 21.9ms\n",
      "6:\tlearn: 0.5405841\ttotal: 10.8ms\tremaining: 20.1ms\n",
      "7:\tlearn: 0.5263891\ttotal: 12.2ms\tremaining: 18.3ms\n",
      "8:\tlearn: 0.5131008\ttotal: 13.6ms\tremaining: 16.6ms\n",
      "9:\tlearn: 0.5012873\ttotal: 15ms\tremaining: 15ms\n",
      "10:\tlearn: 0.4902005\ttotal: 16.3ms\tremaining: 13.3ms\n",
      "11:\tlearn: 0.4802155\ttotal: 17.6ms\tremaining: 11.8ms\n",
      "12:\tlearn: 0.4721513\ttotal: 19ms\tremaining: 10.2ms\n",
      "13:\tlearn: 0.4629188\ttotal: 20.8ms\tremaining: 8.92ms\n",
      "14:\tlearn: 0.4556197\ttotal: 22.4ms\tremaining: 7.46ms\n",
      "15:\tlearn: 0.4490957\ttotal: 23.9ms\tremaining: 5.99ms\n",
      "16:\tlearn: 0.4427093\ttotal: 25.4ms\tremaining: 4.48ms\n",
      "17:\tlearn: 0.4362751\ttotal: 26.8ms\tremaining: 2.97ms\n",
      "18:\tlearn: 0.4297218\ttotal: 28.2ms\tremaining: 1.48ms\n",
      "19:\tlearn: 0.4239974\ttotal: 29.6ms\tremaining: 0us\n",
      "0:\tlearn: 0.6608893\ttotal: 1.33ms\tremaining: 25.3ms\n",
      "1:\tlearn: 0.6361483\ttotal: 2.54ms\tremaining: 22.9ms\n",
      "2:\tlearn: 0.6121262\ttotal: 3.92ms\tremaining: 22.2ms\n",
      "3:\tlearn: 0.5905561\ttotal: 5.29ms\tremaining: 21.2ms\n",
      "4:\tlearn: 0.5699661\ttotal: 6.69ms\tremaining: 20.1ms\n",
      "5:\tlearn: 0.5541383\ttotal: 8.07ms\tremaining: 18.8ms\n",
      "6:\tlearn: 0.5390748\ttotal: 9.42ms\tremaining: 17.5ms\n",
      "7:\tlearn: 0.5227779\ttotal: 10.7ms\tremaining: 16.1ms\n",
      "8:\tlearn: 0.5092609\ttotal: 12ms\tremaining: 14.7ms\n",
      "9:\tlearn: 0.4979464\ttotal: 13.3ms\tremaining: 13.3ms\n",
      "10:\tlearn: 0.4870635\ttotal: 14.6ms\tremaining: 12ms\n",
      "11:\tlearn: 0.4757349\ttotal: 15.9ms\tremaining: 10.6ms\n",
      "12:\tlearn: 0.4663043\ttotal: 17.2ms\tremaining: 9.25ms\n",
      "13:\tlearn: 0.4567593\ttotal: 18.5ms\tremaining: 7.92ms\n",
      "14:\tlearn: 0.4479936\ttotal: 22ms\tremaining: 7.33ms\n",
      "15:\tlearn: 0.4414207\ttotal: 23.6ms\tremaining: 5.89ms\n",
      "16:\tlearn: 0.4336361\ttotal: 24.8ms\tremaining: 4.38ms\n",
      "17:\tlearn: 0.4274733\ttotal: 26ms\tremaining: 2.89ms\n",
      "18:\tlearn: 0.4218794\ttotal: 27.1ms\tremaining: 1.43ms\n",
      "19:\tlearn: 0.4151458\ttotal: 28.2ms\tremaining: 0us\n",
      "0:\tlearn: 0.6573279\ttotal: 1.24ms\tremaining: 23.6ms\n",
      "1:\tlearn: 0.6293284\ttotal: 2.52ms\tremaining: 22.6ms\n",
      "2:\tlearn: 0.6063918\ttotal: 3.66ms\tremaining: 20.7ms\n",
      "3:\tlearn: 0.5835844\ttotal: 4.72ms\tremaining: 18.9ms\n",
      "4:\tlearn: 0.5664251\ttotal: 5.78ms\tremaining: 17.3ms\n",
      "5:\tlearn: 0.5491618\ttotal: 6.88ms\tremaining: 16.1ms\n",
      "6:\tlearn: 0.5330715\ttotal: 8.03ms\tremaining: 14.9ms\n",
      "7:\tlearn: 0.5196095\ttotal: 9.33ms\tremaining: 14ms\n",
      "8:\tlearn: 0.5067260\ttotal: 10.7ms\tremaining: 13.1ms\n",
      "9:\tlearn: 0.4967653\ttotal: 12ms\tremaining: 12ms\n",
      "10:\tlearn: 0.4870509\ttotal: 13.2ms\tremaining: 10.8ms\n",
      "11:\tlearn: 0.4767676\ttotal: 14.4ms\tremaining: 9.57ms\n",
      "12:\tlearn: 0.4684103\ttotal: 15.5ms\tremaining: 8.32ms\n",
      "13:\tlearn: 0.4584623\ttotal: 16.5ms\tremaining: 7.09ms\n",
      "14:\tlearn: 0.4506233\ttotal: 17.6ms\tremaining: 5.88ms\n",
      "15:\tlearn: 0.4432395\ttotal: 18.7ms\tremaining: 4.68ms\n",
      "16:\tlearn: 0.4365491\ttotal: 19.8ms\tremaining: 3.49ms\n",
      "17:\tlearn: 0.4301096\ttotal: 20.9ms\tremaining: 2.32ms\n",
      "18:\tlearn: 0.4252229\ttotal: 21.9ms\tremaining: 1.15ms\n",
      "19:\tlearn: 0.4187241\ttotal: 23ms\tremaining: 0us\n",
      "0:\tlearn: 0.6600755\ttotal: 1.13ms\tremaining: 21.5ms\n",
      "1:\tlearn: 0.6338017\ttotal: 2.28ms\tremaining: 20.5ms\n",
      "2:\tlearn: 0.6118130\ttotal: 3.48ms\tremaining: 19.7ms\n",
      "3:\tlearn: 0.5934190\ttotal: 4.77ms\tremaining: 19.1ms\n",
      "4:\tlearn: 0.5754654\ttotal: 6.59ms\tremaining: 19.8ms\n",
      "5:\tlearn: 0.5573057\ttotal: 8.14ms\tremaining: 19ms\n",
      "6:\tlearn: 0.5420716\ttotal: 9.4ms\tremaining: 17.5ms\n",
      "7:\tlearn: 0.5275255\ttotal: 10.5ms\tremaining: 15.8ms\n",
      "8:\tlearn: 0.5130755\ttotal: 11.6ms\tremaining: 14.2ms\n",
      "9:\tlearn: 0.5033686\ttotal: 12.7ms\tremaining: 12.7ms\n",
      "10:\tlearn: 0.4930316\ttotal: 13.8ms\tremaining: 11.3ms\n",
      "11:\tlearn: 0.4826085\ttotal: 14.9ms\tremaining: 9.94ms\n",
      "12:\tlearn: 0.4730830\ttotal: 16ms\tremaining: 8.62ms\n",
      "13:\tlearn: 0.4645860\ttotal: 17.1ms\tremaining: 7.33ms\n",
      "14:\tlearn: 0.4564957\ttotal: 18.4ms\tremaining: 6.12ms\n",
      "15:\tlearn: 0.4494008\ttotal: 20ms\tremaining: 4.99ms\n",
      "16:\tlearn: 0.4426751\ttotal: 21.3ms\tremaining: 3.75ms\n",
      "17:\tlearn: 0.4366080\ttotal: 22.8ms\tremaining: 2.53ms\n",
      "18:\tlearn: 0.4321851\ttotal: 24.1ms\tremaining: 1.27ms\n",
      "19:\tlearn: 0.4265050\ttotal: 25.3ms\tremaining: 0us\n",
      "0:\tlearn: 0.6619258\ttotal: 34.1ms\tremaining: 648ms\n",
      "1:\tlearn: 0.6359788\ttotal: 67.6ms\tremaining: 609ms\n",
      "2:\tlearn: 0.6126675\ttotal: 103ms\tremaining: 581ms\n",
      "3:\tlearn: 0.5931944\ttotal: 140ms\tremaining: 562ms\n",
      "4:\tlearn: 0.5727240\ttotal: 174ms\tremaining: 521ms\n",
      "5:\tlearn: 0.5561767\ttotal: 208ms\tremaining: 486ms\n",
      "6:\tlearn: 0.5382193\ttotal: 248ms\tremaining: 460ms\n",
      "7:\tlearn: 0.5211412\ttotal: 283ms\tremaining: 425ms\n",
      "8:\tlearn: 0.5070535\ttotal: 320ms\tremaining: 392ms\n",
      "9:\tlearn: 0.4945445\ttotal: 358ms\tremaining: 358ms\n",
      "10:\tlearn: 0.4816074\ttotal: 393ms\tremaining: 322ms\n",
      "11:\tlearn: 0.4699566\ttotal: 429ms\tremaining: 286ms\n",
      "12:\tlearn: 0.4577802\ttotal: 465ms\tremaining: 250ms\n",
      "13:\tlearn: 0.4463042\ttotal: 501ms\tremaining: 215ms\n",
      "14:\tlearn: 0.4372558\ttotal: 540ms\tremaining: 180ms\n",
      "15:\tlearn: 0.4282778\ttotal: 578ms\tremaining: 145ms\n",
      "16:\tlearn: 0.4196916\ttotal: 611ms\tremaining: 108ms\n",
      "17:\tlearn: 0.4114369\ttotal: 646ms\tremaining: 71.8ms\n",
      "18:\tlearn: 0.4032026\ttotal: 685ms\tremaining: 36.1ms\n",
      "19:\tlearn: 0.3954884\ttotal: 725ms\tremaining: 0us\n",
      "0:\tlearn: 0.6629773\ttotal: 32.2ms\tremaining: 612ms\n",
      "1:\tlearn: 0.6403895\ttotal: 64.9ms\tremaining: 584ms\n",
      "2:\tlearn: 0.6161531\ttotal: 98.5ms\tremaining: 558ms\n",
      "3:\tlearn: 0.5943814\ttotal: 135ms\tremaining: 541ms\n",
      "4:\tlearn: 0.5750596\ttotal: 172ms\tremaining: 515ms\n",
      "5:\tlearn: 0.5593701\ttotal: 208ms\tremaining: 485ms\n",
      "6:\tlearn: 0.5424694\ttotal: 245ms\tremaining: 455ms\n",
      "7:\tlearn: 0.5268736\ttotal: 278ms\tremaining: 416ms\n",
      "8:\tlearn: 0.5122066\ttotal: 312ms\tremaining: 381ms\n",
      "9:\tlearn: 0.4994171\ttotal: 347ms\tremaining: 347ms\n",
      "10:\tlearn: 0.4870649\ttotal: 383ms\tremaining: 313ms\n",
      "11:\tlearn: 0.4738711\ttotal: 418ms\tremaining: 279ms\n",
      "12:\tlearn: 0.4615355\ttotal: 455ms\tremaining: 245ms\n",
      "13:\tlearn: 0.4516901\ttotal: 491ms\tremaining: 211ms\n",
      "14:\tlearn: 0.4406675\ttotal: 535ms\tremaining: 178ms\n",
      "15:\tlearn: 0.4320576\ttotal: 572ms\tremaining: 143ms\n",
      "16:\tlearn: 0.4217784\ttotal: 612ms\tremaining: 108ms\n",
      "17:\tlearn: 0.4144164\ttotal: 653ms\tremaining: 72.6ms\n",
      "18:\tlearn: 0.4056428\ttotal: 690ms\tremaining: 36.3ms\n",
      "19:\tlearn: 0.3972942\ttotal: 724ms\tremaining: 0us\n",
      "0:\tlearn: 0.6649679\ttotal: 36.8ms\tremaining: 699ms\n",
      "1:\tlearn: 0.6391424\ttotal: 78.4ms\tremaining: 705ms\n",
      "2:\tlearn: 0.6166852\ttotal: 115ms\tremaining: 654ms\n",
      "3:\tlearn: 0.5963640\ttotal: 149ms\tremaining: 598ms\n",
      "4:\tlearn: 0.5729833\ttotal: 184ms\tremaining: 551ms\n",
      "5:\tlearn: 0.5570252\ttotal: 219ms\tremaining: 511ms\n",
      "6:\tlearn: 0.5380517\ttotal: 253ms\tremaining: 471ms\n",
      "7:\tlearn: 0.5211778\ttotal: 293ms\tremaining: 440ms\n",
      "8:\tlearn: 0.5067834\ttotal: 333ms\tremaining: 407ms\n",
      "9:\tlearn: 0.4942221\ttotal: 369ms\tremaining: 369ms\n",
      "10:\tlearn: 0.4818639\ttotal: 404ms\tremaining: 330ms\n",
      "11:\tlearn: 0.4691794\ttotal: 439ms\tremaining: 293ms\n",
      "12:\tlearn: 0.4576049\ttotal: 478ms\tremaining: 257ms\n",
      "13:\tlearn: 0.4460181\ttotal: 516ms\tremaining: 221ms\n",
      "14:\tlearn: 0.4377510\ttotal: 554ms\tremaining: 185ms\n",
      "15:\tlearn: 0.4290762\ttotal: 592ms\tremaining: 148ms\n",
      "16:\tlearn: 0.4205088\ttotal: 626ms\tremaining: 110ms\n",
      "17:\tlearn: 0.4122570\ttotal: 660ms\tremaining: 73.3ms\n",
      "18:\tlearn: 0.4033871\ttotal: 697ms\tremaining: 36.7ms\n",
      "19:\tlearn: 0.3953419\ttotal: 736ms\tremaining: 0us\n",
      "0:\tlearn: 0.6643853\ttotal: 39.5ms\tremaining: 751ms\n",
      "1:\tlearn: 0.6377091\ttotal: 79.3ms\tremaining: 714ms\n",
      "2:\tlearn: 0.6140719\ttotal: 115ms\tremaining: 650ms\n",
      "3:\tlearn: 0.5927953\ttotal: 151ms\tremaining: 602ms\n",
      "4:\tlearn: 0.5722767\ttotal: 187ms\tremaining: 562ms\n",
      "5:\tlearn: 0.5559357\ttotal: 226ms\tremaining: 528ms\n",
      "6:\tlearn: 0.5375066\ttotal: 259ms\tremaining: 481ms\n",
      "7:\tlearn: 0.5208140\ttotal: 293ms\tremaining: 440ms\n",
      "8:\tlearn: 0.5061819\ttotal: 328ms\tremaining: 401ms\n",
      "9:\tlearn: 0.4934151\ttotal: 363ms\tremaining: 363ms\n",
      "10:\tlearn: 0.4811465\ttotal: 405ms\tremaining: 332ms\n",
      "11:\tlearn: 0.4684582\ttotal: 441ms\tremaining: 294ms\n",
      "12:\tlearn: 0.4575150\ttotal: 476ms\tremaining: 257ms\n",
      "13:\tlearn: 0.4476272\ttotal: 510ms\tremaining: 219ms\n",
      "14:\tlearn: 0.4382331\ttotal: 544ms\tremaining: 181ms\n",
      "15:\tlearn: 0.4294184\ttotal: 576ms\tremaining: 144ms\n",
      "16:\tlearn: 0.4207885\ttotal: 614ms\tremaining: 108ms\n",
      "17:\tlearn: 0.4125565\ttotal: 652ms\tremaining: 72.5ms\n",
      "18:\tlearn: 0.4043804\ttotal: 688ms\tremaining: 36.2ms\n",
      "19:\tlearn: 0.3980125\ttotal: 721ms\tremaining: 0us\n",
      "0:\tlearn: 0.6633220\ttotal: 34.4ms\tremaining: 653ms\n",
      "1:\tlearn: 0.6375598\ttotal: 69.8ms\tremaining: 628ms\n",
      "2:\tlearn: 0.6168046\ttotal: 108ms\tremaining: 613ms\n",
      "3:\tlearn: 0.5964160\ttotal: 143ms\tremaining: 573ms\n",
      "4:\tlearn: 0.5743257\ttotal: 179ms\tremaining: 538ms\n",
      "5:\tlearn: 0.5589054\ttotal: 212ms\tremaining: 495ms\n",
      "6:\tlearn: 0.5419080\ttotal: 246ms\tremaining: 456ms\n",
      "7:\tlearn: 0.5272134\ttotal: 284ms\tremaining: 425ms\n",
      "8:\tlearn: 0.5135079\ttotal: 320ms\tremaining: 391ms\n",
      "9:\tlearn: 0.5021653\ttotal: 355ms\tremaining: 355ms\n",
      "10:\tlearn: 0.4890641\ttotal: 388ms\tremaining: 318ms\n",
      "11:\tlearn: 0.4764495\ttotal: 421ms\tremaining: 281ms\n",
      "12:\tlearn: 0.4644401\ttotal: 455ms\tremaining: 245ms\n",
      "13:\tlearn: 0.4532775\ttotal: 492ms\tremaining: 211ms\n",
      "14:\tlearn: 0.4437780\ttotal: 528ms\tremaining: 176ms\n",
      "15:\tlearn: 0.4348143\ttotal: 567ms\tremaining: 142ms\n",
      "16:\tlearn: 0.4258943\ttotal: 603ms\tremaining: 106ms\n",
      "17:\tlearn: 0.4183907\ttotal: 639ms\tremaining: 71ms\n",
      "18:\tlearn: 0.4108985\ttotal: 674ms\tremaining: 35.5ms\n",
      "19:\tlearn: 0.4026630\ttotal: 710ms\tremaining: 0us\n",
      "0:\tlearn: 0.5933329\ttotal: 1.45ms\tremaining: 15.9ms\n",
      "1:\tlearn: 0.5397785\ttotal: 3.24ms\tremaining: 16.2ms\n",
      "2:\tlearn: 0.5038450\ttotal: 4.67ms\tremaining: 14ms\n",
      "3:\tlearn: 0.4697238\ttotal: 6.46ms\tremaining: 12.9ms\n",
      "4:\tlearn: 0.4471969\ttotal: 7.89ms\tremaining: 11.1ms\n",
      "5:\tlearn: 0.4292741\ttotal: 9.24ms\tremaining: 9.24ms\n",
      "6:\tlearn: 0.4162816\ttotal: 10.6ms\tremaining: 7.58ms\n",
      "7:\tlearn: 0.4015901\ttotal: 11.9ms\tremaining: 5.95ms\n",
      "8:\tlearn: 0.3894009\ttotal: 13.3ms\tremaining: 4.43ms\n",
      "9:\tlearn: 0.3788938\ttotal: 14.7ms\tremaining: 2.93ms\n",
      "10:\tlearn: 0.3707797\ttotal: 16ms\tremaining: 1.45ms\n",
      "11:\tlearn: 0.3630786\ttotal: 17.3ms\tremaining: 0us\n",
      "0:\tlearn: 0.5985146\ttotal: 1.72ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.5465378\ttotal: 3.42ms\tremaining: 17.1ms\n",
      "2:\tlearn: 0.5099730\ttotal: 5.14ms\tremaining: 15.4ms\n",
      "3:\tlearn: 0.4770432\ttotal: 6.85ms\tremaining: 13.7ms\n",
      "4:\tlearn: 0.4552464\ttotal: 8.23ms\tremaining: 11.5ms\n",
      "5:\tlearn: 0.4327142\ttotal: 9.62ms\tremaining: 9.62ms\n",
      "6:\tlearn: 0.4174385\ttotal: 11ms\tremaining: 7.85ms\n",
      "7:\tlearn: 0.4062887\ttotal: 12.3ms\tremaining: 6.16ms\n",
      "8:\tlearn: 0.3953315\ttotal: 13.7ms\tremaining: 4.55ms\n",
      "9:\tlearn: 0.3812544\ttotal: 14.9ms\tremaining: 2.99ms\n",
      "10:\tlearn: 0.3745025\ttotal: 16.2ms\tremaining: 1.47ms\n",
      "11:\tlearn: 0.3666718\ttotal: 19.5ms\tremaining: 0us\n",
      "0:\tlearn: 0.6051200\ttotal: 1.64ms\tremaining: 18ms\n",
      "1:\tlearn: 0.5523224\ttotal: 3.21ms\tremaining: 16.1ms\n",
      "2:\tlearn: 0.5115040\ttotal: 4.68ms\tremaining: 14ms\n",
      "3:\tlearn: 0.4768175\ttotal: 6.04ms\tremaining: 12.1ms\n",
      "4:\tlearn: 0.4535562\ttotal: 7.51ms\tremaining: 10.5ms\n",
      "5:\tlearn: 0.4305391\ttotal: 8.89ms\tremaining: 8.89ms\n",
      "6:\tlearn: 0.4158435\ttotal: 10.2ms\tremaining: 7.27ms\n",
      "7:\tlearn: 0.3976979\ttotal: 11.5ms\tremaining: 5.77ms\n",
      "8:\tlearn: 0.3878514\ttotal: 12.8ms\tremaining: 4.26ms\n",
      "9:\tlearn: 0.3781544\ttotal: 14.1ms\tremaining: 2.82ms\n",
      "10:\tlearn: 0.3685276\ttotal: 15.7ms\tremaining: 1.43ms\n",
      "11:\tlearn: 0.3592169\ttotal: 17.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.5952236\ttotal: 1.53ms\tremaining: 16.9ms\n",
      "1:\tlearn: 0.5452341\ttotal: 3.13ms\tremaining: 15.7ms\n",
      "2:\tlearn: 0.5119100\ttotal: 4.53ms\tremaining: 13.6ms\n",
      "3:\tlearn: 0.4765739\ttotal: 5.91ms\tremaining: 11.8ms\n",
      "4:\tlearn: 0.4550524\ttotal: 7.28ms\tremaining: 10.2ms\n",
      "5:\tlearn: 0.4342325\ttotal: 8.6ms\tremaining: 8.6ms\n",
      "6:\tlearn: 0.4232518\ttotal: 10ms\tremaining: 7.15ms\n",
      "7:\tlearn: 0.4087695\ttotal: 11.3ms\tremaining: 5.65ms\n",
      "8:\tlearn: 0.3993415\ttotal: 12.7ms\tremaining: 4.22ms\n",
      "9:\tlearn: 0.3882570\ttotal: 14ms\tremaining: 2.81ms\n",
      "10:\tlearn: 0.3793803\ttotal: 15.5ms\tremaining: 1.41ms\n",
      "11:\tlearn: 0.3686000\ttotal: 16.9ms\tremaining: 0us\n",
      "0:\tlearn: 0.6032448\ttotal: 4.58ms\tremaining: 50.4ms\n",
      "1:\tlearn: 0.5487735\ttotal: 9.55ms\tremaining: 47.8ms\n",
      "2:\tlearn: 0.5049552\ttotal: 15.6ms\tremaining: 46.8ms\n",
      "3:\tlearn: 0.4725282\ttotal: 20.8ms\tremaining: 41.7ms\n",
      "4:\tlearn: 0.4513038\ttotal: 25.4ms\tremaining: 35.5ms\n",
      "5:\tlearn: 0.4331013\ttotal: 30.6ms\tremaining: 30.6ms\n",
      "6:\tlearn: 0.4199525\ttotal: 35.5ms\tremaining: 25.4ms\n",
      "7:\tlearn: 0.4063131\ttotal: 40.2ms\tremaining: 20.1ms\n",
      "8:\tlearn: 0.3936399\ttotal: 45.1ms\tremaining: 15ms\n",
      "9:\tlearn: 0.3796335\ttotal: 50ms\tremaining: 9.99ms\n",
      "10:\tlearn: 0.3722836\ttotal: 53.6ms\tremaining: 4.87ms\n",
      "11:\tlearn: 0.3604190\ttotal: 57ms\tremaining: 0us\n",
      "0:\tlearn: 0.6893259\ttotal: 1.47ms\tremaining: 35.4ms\n",
      "1:\tlearn: 0.6862439\ttotal: 2.87ms\tremaining: 33ms\n",
      "2:\tlearn: 0.6833452\ttotal: 4.15ms\tremaining: 30.4ms\n",
      "3:\tlearn: 0.6803430\ttotal: 5.47ms\tremaining: 28.7ms\n",
      "4:\tlearn: 0.6769899\ttotal: 6.92ms\tremaining: 27.7ms\n",
      "5:\tlearn: 0.6744031\ttotal: 8.35ms\tremaining: 26.4ms\n",
      "6:\tlearn: 0.6715289\ttotal: 9.81ms\tremaining: 25.2ms\n",
      "7:\tlearn: 0.6681810\ttotal: 11.3ms\tremaining: 24ms\n",
      "8:\tlearn: 0.6650086\ttotal: 12.5ms\tremaining: 22.2ms\n",
      "9:\tlearn: 0.6621330\ttotal: 13.7ms\tremaining: 20.5ms\n",
      "10:\tlearn: 0.6594151\ttotal: 15ms\tremaining: 19.1ms\n",
      "11:\tlearn: 0.6564275\ttotal: 16.3ms\tremaining: 17.7ms\n",
      "12:\tlearn: 0.6533907\ttotal: 17.6ms\tremaining: 16.3ms\n",
      "13:\tlearn: 0.6503371\ttotal: 18.8ms\tremaining: 14.7ms\n",
      "14:\tlearn: 0.6474761\ttotal: 20ms\tremaining: 13.3ms\n",
      "15:\tlearn: 0.6448255\ttotal: 21.1ms\tremaining: 11.9ms\n",
      "16:\tlearn: 0.6419346\ttotal: 22.4ms\tremaining: 10.5ms\n",
      "17:\tlearn: 0.6389428\ttotal: 23.5ms\tremaining: 9.14ms\n",
      "18:\tlearn: 0.6360564\ttotal: 24.8ms\tremaining: 7.82ms\n",
      "19:\tlearn: 0.6332035\ttotal: 26.4ms\tremaining: 6.59ms\n",
      "20:\tlearn: 0.6305589\ttotal: 27.5ms\tremaining: 5.24ms\n",
      "21:\tlearn: 0.6282136\ttotal: 28.7ms\tremaining: 3.91ms\n",
      "22:\tlearn: 0.6255333\ttotal: 29.7ms\tremaining: 2.58ms\n",
      "23:\tlearn: 0.6229869\ttotal: 30.7ms\tremaining: 1.28ms\n",
      "24:\tlearn: 0.6205025\ttotal: 31.8ms\tremaining: 0us\n",
      "0:\tlearn: 0.6895335\ttotal: 1.12ms\tremaining: 26.9ms\n",
      "1:\tlearn: 0.6864673\ttotal: 2.35ms\tremaining: 27ms\n",
      "2:\tlearn: 0.6834538\ttotal: 3.45ms\tremaining: 25.3ms\n",
      "3:\tlearn: 0.6805087\ttotal: 4.43ms\tremaining: 23.3ms\n",
      "4:\tlearn: 0.6772777\ttotal: 5.45ms\tremaining: 21.8ms\n",
      "5:\tlearn: 0.6741862\ttotal: 6.64ms\tremaining: 21ms\n",
      "6:\tlearn: 0.6712595\ttotal: 7.76ms\tremaining: 20ms\n",
      "7:\tlearn: 0.6682346\ttotal: 8.84ms\tremaining: 18.8ms\n",
      "8:\tlearn: 0.6651315\ttotal: 9.89ms\tremaining: 17.6ms\n",
      "9:\tlearn: 0.6621485\ttotal: 11ms\tremaining: 16.4ms\n",
      "10:\tlearn: 0.6594726\ttotal: 12.2ms\tremaining: 15.5ms\n",
      "11:\tlearn: 0.6565618\ttotal: 13.2ms\tremaining: 14.3ms\n",
      "12:\tlearn: 0.6538763\ttotal: 14.3ms\tremaining: 13.2ms\n",
      "13:\tlearn: 0.6509952\ttotal: 15.3ms\tremaining: 12.1ms\n",
      "14:\tlearn: 0.6481423\ttotal: 16.4ms\tremaining: 10.9ms\n",
      "15:\tlearn: 0.6459133\ttotal: 17.4ms\tremaining: 9.8ms\n",
      "16:\tlearn: 0.6431006\ttotal: 18.4ms\tremaining: 8.67ms\n",
      "17:\tlearn: 0.6404731\ttotal: 19.5ms\tremaining: 7.56ms\n",
      "18:\tlearn: 0.6377856\ttotal: 20.4ms\tremaining: 6.46ms\n",
      "19:\tlearn: 0.6350516\ttotal: 21.7ms\tremaining: 5.42ms\n",
      "20:\tlearn: 0.6325437\ttotal: 22.9ms\tremaining: 4.35ms\n",
      "21:\tlearn: 0.6302034\ttotal: 24.7ms\tremaining: 3.36ms\n",
      "22:\tlearn: 0.6277572\ttotal: 25.9ms\tremaining: 2.25ms\n",
      "23:\tlearn: 0.6253256\ttotal: 27ms\tremaining: 1.13ms\n",
      "24:\tlearn: 0.6228561\ttotal: 28.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6897890\ttotal: 1.16ms\tremaining: 27.9ms\n",
      "1:\tlearn: 0.6868723\ttotal: 2.36ms\tremaining: 27.2ms\n",
      "2:\tlearn: 0.6833212\ttotal: 3.36ms\tremaining: 24.7ms\n",
      "3:\tlearn: 0.6802409\ttotal: 4.48ms\tremaining: 23.5ms\n",
      "4:\tlearn: 0.6769411\ttotal: 5.55ms\tremaining: 22.2ms\n",
      "5:\tlearn: 0.6736541\ttotal: 6.6ms\tremaining: 20.9ms\n",
      "6:\tlearn: 0.6707575\ttotal: 7.61ms\tremaining: 19.6ms\n",
      "7:\tlearn: 0.6677034\ttotal: 8.64ms\tremaining: 18.4ms\n",
      "8:\tlearn: 0.6642094\ttotal: 9.68ms\tremaining: 17.2ms\n",
      "9:\tlearn: 0.6614527\ttotal: 11ms\tremaining: 16.5ms\n",
      "10:\tlearn: 0.6585154\ttotal: 13.7ms\tremaining: 17.4ms\n",
      "11:\tlearn: 0.6554694\ttotal: 14.9ms\tremaining: 16.2ms\n",
      "12:\tlearn: 0.6524940\ttotal: 16ms\tremaining: 14.8ms\n",
      "13:\tlearn: 0.6496846\ttotal: 17.2ms\tremaining: 13.5ms\n",
      "14:\tlearn: 0.6468242\ttotal: 18.3ms\tremaining: 12.2ms\n",
      "15:\tlearn: 0.6441929\ttotal: 19.3ms\tremaining: 10.9ms\n",
      "16:\tlearn: 0.6411685\ttotal: 20.4ms\tremaining: 9.6ms\n",
      "17:\tlearn: 0.6384523\ttotal: 21.4ms\tremaining: 8.34ms\n",
      "18:\tlearn: 0.6357976\ttotal: 22.4ms\tremaining: 7.09ms\n",
      "19:\tlearn: 0.6329645\ttotal: 23.8ms\tremaining: 5.96ms\n",
      "20:\tlearn: 0.6302037\ttotal: 25.1ms\tremaining: 4.77ms\n",
      "21:\tlearn: 0.6277465\ttotal: 26.8ms\tremaining: 3.65ms\n",
      "22:\tlearn: 0.6251740\ttotal: 28.1ms\tremaining: 2.44ms\n",
      "23:\tlearn: 0.6227045\ttotal: 29.5ms\tremaining: 1.23ms\n",
      "24:\tlearn: 0.6202462\ttotal: 30.6ms\tremaining: 0us\n",
      "0:\tlearn: 0.6894206\ttotal: 1.24ms\tremaining: 29.9ms\n",
      "1:\tlearn: 0.6863474\ttotal: 2.57ms\tremaining: 29.6ms\n",
      "2:\tlearn: 0.6836265\ttotal: 3.84ms\tremaining: 28.2ms\n",
      "3:\tlearn: 0.6805582\ttotal: 5.03ms\tremaining: 26.4ms\n",
      "4:\tlearn: 0.6773105\ttotal: 6.24ms\tremaining: 24.9ms\n",
      "5:\tlearn: 0.6742094\ttotal: 7.32ms\tremaining: 23.2ms\n",
      "6:\tlearn: 0.6715747\ttotal: 8.42ms\tremaining: 21.6ms\n",
      "7:\tlearn: 0.6687559\ttotal: 9.55ms\tremaining: 20.3ms\n",
      "8:\tlearn: 0.6655838\ttotal: 10.6ms\tremaining: 18.8ms\n",
      "9:\tlearn: 0.6626435\ttotal: 11.7ms\tremaining: 17.5ms\n",
      "10:\tlearn: 0.6599140\ttotal: 14.2ms\tremaining: 18.1ms\n",
      "11:\tlearn: 0.6570400\ttotal: 15.3ms\tremaining: 16.6ms\n",
      "12:\tlearn: 0.6539608\ttotal: 16.4ms\tremaining: 15.1ms\n",
      "13:\tlearn: 0.6510312\ttotal: 17.8ms\tremaining: 14ms\n",
      "14:\tlearn: 0.6480655\ttotal: 19.3ms\tremaining: 12.9ms\n",
      "15:\tlearn: 0.6455782\ttotal: 20.7ms\tremaining: 11.7ms\n",
      "16:\tlearn: 0.6428099\ttotal: 22ms\tremaining: 10.4ms\n",
      "17:\tlearn: 0.6399952\ttotal: 23.2ms\tremaining: 9.01ms\n",
      "18:\tlearn: 0.6373696\ttotal: 24.4ms\tremaining: 7.7ms\n",
      "19:\tlearn: 0.6346566\ttotal: 25.5ms\tremaining: 6.37ms\n",
      "20:\tlearn: 0.6316682\ttotal: 26.6ms\tremaining: 5.06ms\n",
      "21:\tlearn: 0.6292484\ttotal: 27.6ms\tremaining: 3.76ms\n",
      "22:\tlearn: 0.6265402\ttotal: 29ms\tremaining: 2.52ms\n",
      "23:\tlearn: 0.6243173\ttotal: 31ms\tremaining: 1.29ms\n",
      "24:\tlearn: 0.6219639\ttotal: 32.7ms\tremaining: 0us\n",
      "0:\tlearn: 0.6896989\ttotal: 1.33ms\tremaining: 31.9ms\n",
      "1:\tlearn: 0.6865867\ttotal: 2.61ms\tremaining: 30ms\n",
      "2:\tlearn: 0.6834983\ttotal: 3.81ms\tremaining: 28ms\n",
      "3:\tlearn: 0.6805516\ttotal: 4.98ms\tremaining: 26.2ms\n",
      "4:\tlearn: 0.6774074\ttotal: 6.09ms\tremaining: 24.4ms\n",
      "5:\tlearn: 0.6743768\ttotal: 7.38ms\tremaining: 23.4ms\n",
      "6:\tlearn: 0.6717885\ttotal: 8.75ms\tremaining: 22.5ms\n",
      "7:\tlearn: 0.6687552\ttotal: 10.1ms\tremaining: 21.4ms\n",
      "8:\tlearn: 0.6656772\ttotal: 11.4ms\tremaining: 20.2ms\n",
      "9:\tlearn: 0.6625880\ttotal: 12.6ms\tremaining: 18.9ms\n",
      "10:\tlearn: 0.6598630\ttotal: 13.9ms\tremaining: 17.7ms\n",
      "11:\tlearn: 0.6568965\ttotal: 15.7ms\tremaining: 17ms\n",
      "12:\tlearn: 0.6539349\ttotal: 17.2ms\tremaining: 15.9ms\n",
      "13:\tlearn: 0.6510798\ttotal: 18.4ms\tremaining: 14.5ms\n",
      "14:\tlearn: 0.6481610\ttotal: 19.7ms\tremaining: 13.1ms\n",
      "15:\tlearn: 0.6456188\ttotal: 20.9ms\tremaining: 11.7ms\n",
      "16:\tlearn: 0.6429290\ttotal: 22ms\tremaining: 10.3ms\n",
      "17:\tlearn: 0.6403313\ttotal: 23.1ms\tremaining: 8.98ms\n",
      "18:\tlearn: 0.6376502\ttotal: 24.2ms\tremaining: 7.65ms\n",
      "19:\tlearn: 0.6348462\ttotal: 25.3ms\tremaining: 6.33ms\n",
      "20:\tlearn: 0.6322093\ttotal: 26.4ms\tremaining: 5.04ms\n",
      "21:\tlearn: 0.6298492\ttotal: 27.7ms\tremaining: 3.77ms\n",
      "22:\tlearn: 0.6274429\ttotal: 28.9ms\tremaining: 2.52ms\n",
      "23:\tlearn: 0.6250254\ttotal: 30.1ms\tremaining: 1.25ms\n",
      "24:\tlearn: 0.6225957\ttotal: 31.4ms\tremaining: 0us\n",
      "0:\tlearn: 0.6574592\ttotal: 689us\tremaining: 13.1ms\n",
      "1:\tlearn: 0.6314555\ttotal: 1.4ms\tremaining: 12.6ms\n",
      "2:\tlearn: 0.6076125\ttotal: 2.14ms\tremaining: 12.1ms\n",
      "3:\tlearn: 0.5871185\ttotal: 2.83ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.5683300\ttotal: 3.47ms\tremaining: 10.4ms\n",
      "5:\tlearn: 0.5522690\ttotal: 4.18ms\tremaining: 9.76ms\n",
      "6:\tlearn: 0.5379274\ttotal: 4.83ms\tremaining: 8.97ms\n",
      "7:\tlearn: 0.5237744\ttotal: 5.49ms\tremaining: 8.23ms\n",
      "8:\tlearn: 0.5127963\ttotal: 6.17ms\tremaining: 7.54ms\n",
      "9:\tlearn: 0.5023071\ttotal: 6.84ms\tremaining: 6.84ms\n",
      "10:\tlearn: 0.4942812\ttotal: 7.47ms\tremaining: 6.12ms\n",
      "11:\tlearn: 0.4851586\ttotal: 8.13ms\tremaining: 5.42ms\n",
      "12:\tlearn: 0.4772507\ttotal: 8.77ms\tremaining: 4.72ms\n",
      "13:\tlearn: 0.4682660\ttotal: 9.4ms\tremaining: 4.03ms\n",
      "14:\tlearn: 0.4618124\ttotal: 10.1ms\tremaining: 3.35ms\n",
      "15:\tlearn: 0.4549281\ttotal: 10.7ms\tremaining: 2.68ms\n",
      "16:\tlearn: 0.4499782\ttotal: 11.4ms\tremaining: 2.01ms\n",
      "17:\tlearn: 0.4454808\ttotal: 12ms\tremaining: 1.34ms\n",
      "18:\tlearn: 0.4422121\ttotal: 12.7ms\tremaining: 666us\n",
      "19:\tlearn: 0.4382121\ttotal: 13.4ms\tremaining: 0us\n",
      "0:\tlearn: 0.6581119\ttotal: 643us\tremaining: 12.2ms\n",
      "1:\tlearn: 0.6326203\ttotal: 1.35ms\tremaining: 12.1ms\n",
      "2:\tlearn: 0.6123228\ttotal: 1.96ms\tremaining: 11.1ms\n",
      "3:\tlearn: 0.5930913\ttotal: 2.56ms\tremaining: 10.2ms\n",
      "4:\tlearn: 0.5744641\ttotal: 3.27ms\tremaining: 9.81ms\n",
      "5:\tlearn: 0.5576677\ttotal: 3.94ms\tremaining: 9.2ms\n",
      "6:\tlearn: 0.5415453\ttotal: 4.59ms\tremaining: 8.52ms\n",
      "7:\tlearn: 0.5276069\ttotal: 5.23ms\tremaining: 7.84ms\n",
      "8:\tlearn: 0.5163868\ttotal: 6.55ms\tremaining: 8.01ms\n",
      "9:\tlearn: 0.5054642\ttotal: 7.32ms\tremaining: 7.32ms\n",
      "10:\tlearn: 0.4970401\ttotal: 8.01ms\tremaining: 6.56ms\n",
      "11:\tlearn: 0.4885933\ttotal: 8.66ms\tremaining: 5.78ms\n",
      "12:\tlearn: 0.4806349\ttotal: 9.32ms\tremaining: 5.02ms\n",
      "13:\tlearn: 0.4730936\ttotal: 10ms\tremaining: 4.29ms\n",
      "14:\tlearn: 0.4672890\ttotal: 10.8ms\tremaining: 3.58ms\n",
      "15:\tlearn: 0.4619194\ttotal: 11.4ms\tremaining: 2.86ms\n",
      "16:\tlearn: 0.4563423\ttotal: 12.1ms\tremaining: 2.13ms\n",
      "17:\tlearn: 0.4521653\ttotal: 12.8ms\tremaining: 1.42ms\n",
      "18:\tlearn: 0.4482609\ttotal: 13.4ms\tremaining: 706us\n",
      "19:\tlearn: 0.4422474\ttotal: 14.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6610650\ttotal: 624us\tremaining: 11.9ms\n",
      "1:\tlearn: 0.6351764\ttotal: 1.31ms\tremaining: 11.8ms\n",
      "2:\tlearn: 0.6109274\ttotal: 2.2ms\tremaining: 12.4ms\n",
      "3:\tlearn: 0.5887619\ttotal: 2.89ms\tremaining: 11.6ms\n",
      "4:\tlearn: 0.5681403\ttotal: 3.57ms\tremaining: 10.7ms\n",
      "5:\tlearn: 0.5521758\ttotal: 4.78ms\tremaining: 11.1ms\n",
      "6:\tlearn: 0.5362057\ttotal: 5.45ms\tremaining: 10.1ms\n",
      "7:\tlearn: 0.5218004\ttotal: 6.15ms\tremaining: 9.22ms\n",
      "8:\tlearn: 0.5096305\ttotal: 6.81ms\tremaining: 8.33ms\n",
      "9:\tlearn: 0.4958471\ttotal: 7.45ms\tremaining: 7.45ms\n",
      "10:\tlearn: 0.4878752\ttotal: 8.12ms\tremaining: 6.64ms\n",
      "11:\tlearn: 0.4786412\ttotal: 8.78ms\tremaining: 5.86ms\n",
      "12:\tlearn: 0.4696306\ttotal: 9.44ms\tremaining: 5.08ms\n",
      "13:\tlearn: 0.4611897\ttotal: 10.1ms\tremaining: 4.32ms\n",
      "14:\tlearn: 0.4544530\ttotal: 10.7ms\tremaining: 3.57ms\n",
      "15:\tlearn: 0.4482295\ttotal: 11.4ms\tremaining: 2.84ms\n",
      "16:\tlearn: 0.4424726\ttotal: 12ms\tremaining: 2.12ms\n",
      "17:\tlearn: 0.4379933\ttotal: 12.6ms\tremaining: 1.4ms\n",
      "18:\tlearn: 0.4331546\ttotal: 13.3ms\tremaining: 698us\n",
      "19:\tlearn: 0.4284059\ttotal: 14.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6588640\ttotal: 657us\tremaining: 12.5ms\n",
      "1:\tlearn: 0.6357293\ttotal: 1.45ms\tremaining: 13ms\n",
      "2:\tlearn: 0.6154786\ttotal: 2.16ms\tremaining: 12.2ms\n",
      "3:\tlearn: 0.5963157\ttotal: 2.8ms\tremaining: 11.2ms\n",
      "4:\tlearn: 0.5775961\ttotal: 3.43ms\tremaining: 10.3ms\n",
      "5:\tlearn: 0.5614830\ttotal: 4.08ms\tremaining: 9.53ms\n",
      "6:\tlearn: 0.5459584\ttotal: 4.75ms\tremaining: 8.82ms\n",
      "7:\tlearn: 0.5324950\ttotal: 5.43ms\tremaining: 8.15ms\n",
      "8:\tlearn: 0.5196798\ttotal: 6.13ms\tremaining: 7.5ms\n",
      "9:\tlearn: 0.5077927\ttotal: 6.84ms\tremaining: 6.84ms\n",
      "10:\tlearn: 0.4982289\ttotal: 7.67ms\tremaining: 6.28ms\n",
      "11:\tlearn: 0.4902050\ttotal: 8.57ms\tremaining: 5.71ms\n",
      "12:\tlearn: 0.4815856\ttotal: 9.34ms\tremaining: 5.03ms\n",
      "13:\tlearn: 0.4735507\ttotal: 10.1ms\tremaining: 4.31ms\n",
      "14:\tlearn: 0.4658975\ttotal: 10.7ms\tremaining: 3.57ms\n",
      "15:\tlearn: 0.4599838\ttotal: 11.4ms\tremaining: 2.85ms\n",
      "16:\tlearn: 0.4539138\ttotal: 12.1ms\tremaining: 2.13ms\n",
      "17:\tlearn: 0.4480370\ttotal: 12.8ms\tremaining: 1.42ms\n",
      "18:\tlearn: 0.4451782\ttotal: 13.4ms\tremaining: 707us\n",
      "19:\tlearn: 0.4412584\ttotal: 14.1ms\tremaining: 0us\n",
      "0:\tlearn: 0.6606063\ttotal: 627us\tremaining: 11.9ms\n",
      "1:\tlearn: 0.6357654\ttotal: 1.36ms\tremaining: 12.2ms\n",
      "2:\tlearn: 0.6124531\ttotal: 2.07ms\tremaining: 11.7ms\n",
      "3:\tlearn: 0.5908117\ttotal: 2.72ms\tremaining: 10.9ms\n",
      "4:\tlearn: 0.5707287\ttotal: 3.34ms\tremaining: 10ms\n",
      "5:\tlearn: 0.5545144\ttotal: 4.08ms\tremaining: 9.51ms\n",
      "6:\tlearn: 0.5393289\ttotal: 4.76ms\tremaining: 8.84ms\n",
      "7:\tlearn: 0.5264897\ttotal: 5.4ms\tremaining: 8.11ms\n",
      "8:\tlearn: 0.5141710\ttotal: 6.33ms\tremaining: 7.73ms\n",
      "9:\tlearn: 0.5024075\ttotal: 7.09ms\tremaining: 7.09ms\n",
      "10:\tlearn: 0.4923449\ttotal: 7.79ms\tremaining: 6.37ms\n",
      "11:\tlearn: 0.4840600\ttotal: 8.49ms\tremaining: 5.66ms\n",
      "12:\tlearn: 0.4764215\ttotal: 9.48ms\tremaining: 5.11ms\n",
      "13:\tlearn: 0.4685194\ttotal: 10.2ms\tremaining: 4.39ms\n",
      "14:\tlearn: 0.4625802\ttotal: 11ms\tremaining: 3.67ms\n",
      "15:\tlearn: 0.4564715\ttotal: 11.8ms\tremaining: 2.95ms\n",
      "16:\tlearn: 0.4511030\ttotal: 12.5ms\tremaining: 2.21ms\n",
      "17:\tlearn: 0.4450009\ttotal: 13.3ms\tremaining: 1.48ms\n",
      "18:\tlearn: 0.4417812\ttotal: 14.2ms\tremaining: 747us\n",
      "19:\tlearn: 0.4380607\ttotal: 14.9ms\tremaining: 0us\n",
      "0:\tlearn: 0.6676669\ttotal: 254ms\tremaining: 2.29s\n",
      "1:\tlearn: 0.6451209\ttotal: 517ms\tremaining: 2.07s\n",
      "2:\tlearn: 0.6237748\ttotal: 776ms\tremaining: 1.81s\n",
      "3:\tlearn: 0.6046061\ttotal: 1.03s\tremaining: 1.55s\n",
      "4:\tlearn: 0.5817816\ttotal: 1.3s\tremaining: 1.3s\n",
      "5:\tlearn: 0.5628129\ttotal: 1.61s\tremaining: 1.08s\n",
      "6:\tlearn: 0.5480192\ttotal: 1.93s\tremaining: 828ms\n",
      "7:\tlearn: 0.5329675\ttotal: 2.25s\tremaining: 562ms\n",
      "8:\tlearn: 0.5183912\ttotal: 2.58s\tremaining: 286ms\n",
      "9:\tlearn: 0.5073518\ttotal: 2.87s\tremaining: 0us\n",
      "0:\tlearn: 0.6688110\ttotal: 292ms\tremaining: 2.63s\n",
      "1:\tlearn: 0.6456027\ttotal: 545ms\tremaining: 2.18s\n",
      "2:\tlearn: 0.6225721\ttotal: 805ms\tremaining: 1.88s\n",
      "3:\tlearn: 0.6038625\ttotal: 1.06s\tremaining: 1.59s\n",
      "4:\tlearn: 0.5812564\ttotal: 1.31s\tremaining: 1.31s\n",
      "5:\tlearn: 0.5662088\ttotal: 1.56s\tremaining: 1.04s\n",
      "6:\tlearn: 0.5523471\ttotal: 1.81s\tremaining: 777ms\n",
      "7:\tlearn: 0.5383883\ttotal: 2.08s\tremaining: 519ms\n",
      "8:\tlearn: 0.5224995\ttotal: 2.31s\tremaining: 257ms\n",
      "9:\tlearn: 0.5098964\ttotal: 2.59s\tremaining: 0us\n",
      "0:\tlearn: 0.6678835\ttotal: 245ms\tremaining: 2.21s\n",
      "1:\tlearn: 0.6465240\ttotal: 484ms\tremaining: 1.94s\n",
      "2:\tlearn: 0.6251441\ttotal: 753ms\tremaining: 1.76s\n",
      "3:\tlearn: 0.6074782\ttotal: 1.03s\tremaining: 1.55s\n",
      "4:\tlearn: 0.5853785\ttotal: 1.28s\tremaining: 1.28s\n",
      "5:\tlearn: 0.5680075\ttotal: 1.54s\tremaining: 1.02s\n",
      "6:\tlearn: 0.5517272\ttotal: 1.82s\tremaining: 779ms\n",
      "7:\tlearn: 0.5366272\ttotal: 2.09s\tremaining: 523ms\n",
      "8:\tlearn: 0.5192347\ttotal: 2.23s\tremaining: 248ms\n",
      "9:\tlearn: 0.5069794\ttotal: 2.51s\tremaining: 0us\n",
      "0:\tlearn: 0.6689551\ttotal: 264ms\tremaining: 2.37s\n",
      "1:\tlearn: 0.6462618\ttotal: 548ms\tremaining: 2.19s\n",
      "2:\tlearn: 0.6251618\ttotal: 858ms\tremaining: 2s\n",
      "3:\tlearn: 0.6031345\ttotal: 1.18s\tremaining: 1.77s\n",
      "4:\tlearn: 0.5807825\ttotal: 1.48s\tremaining: 1.48s\n",
      "5:\tlearn: 0.5630734\ttotal: 1.79s\tremaining: 1.19s\n",
      "6:\tlearn: 0.5480769\ttotal: 2.09s\tremaining: 894ms\n",
      "7:\tlearn: 0.5336144\ttotal: 2.39s\tremaining: 599ms\n",
      "8:\tlearn: 0.5167616\ttotal: 2.63s\tremaining: 293ms\n",
      "9:\tlearn: 0.5038354\ttotal: 2.91s\tremaining: 0us\n",
      "0:\tlearn: 0.6649061\ttotal: 266ms\tremaining: 2.39s\n",
      "1:\tlearn: 0.6437978\ttotal: 599ms\tremaining: 2.39s\n",
      "2:\tlearn: 0.6247663\ttotal: 884ms\tremaining: 2.06s\n",
      "3:\tlearn: 0.6029091\ttotal: 1.16s\tremaining: 1.74s\n",
      "4:\tlearn: 0.5821407\ttotal: 1.45s\tremaining: 1.45s\n",
      "5:\tlearn: 0.5653569\ttotal: 1.72s\tremaining: 1.15s\n",
      "6:\tlearn: 0.5514801\ttotal: 2.02s\tremaining: 868ms\n",
      "7:\tlearn: 0.5374984\ttotal: 2.3s\tremaining: 576ms\n",
      "8:\tlearn: 0.5238358\ttotal: 2.6s\tremaining: 289ms\n",
      "9:\tlearn: 0.5097420\ttotal: 2.94s\tremaining: 0us\n",
      "0:\tlearn: 0.5981955\ttotal: 31.8ms\tremaining: 286ms\n",
      "1:\tlearn: 0.5388222\ttotal: 64.7ms\tremaining: 259ms\n",
      "2:\tlearn: 0.4887079\ttotal: 98.3ms\tremaining: 229ms\n",
      "3:\tlearn: 0.4490648\ttotal: 132ms\tremaining: 199ms\n",
      "4:\tlearn: 0.4158082\ttotal: 168ms\tremaining: 168ms\n",
      "5:\tlearn: 0.3930767\ttotal: 205ms\tremaining: 137ms\n",
      "6:\tlearn: 0.3682534\ttotal: 243ms\tremaining: 104ms\n",
      "7:\tlearn: 0.3519342\ttotal: 278ms\tremaining: 69.4ms\n",
      "8:\tlearn: 0.3345734\ttotal: 313ms\tremaining: 34.7ms\n",
      "9:\tlearn: 0.3197145\ttotal: 346ms\tremaining: 0us\n",
      "0:\tlearn: 0.6012641\ttotal: 34.2ms\tremaining: 308ms\n",
      "1:\tlearn: 0.5460566\ttotal: 68.5ms\tremaining: 274ms\n",
      "2:\tlearn: 0.5021515\ttotal: 106ms\tremaining: 246ms\n",
      "3:\tlearn: 0.4599229\ttotal: 139ms\tremaining: 209ms\n",
      "4:\tlearn: 0.4262379\ttotal: 175ms\tremaining: 175ms\n",
      "5:\tlearn: 0.3988795\ttotal: 205ms\tremaining: 137ms\n",
      "6:\tlearn: 0.3730994\ttotal: 242ms\tremaining: 104ms\n",
      "7:\tlearn: 0.3537624\ttotal: 279ms\tremaining: 69.8ms\n",
      "8:\tlearn: 0.3381846\ttotal: 317ms\tremaining: 35.2ms\n",
      "9:\tlearn: 0.3225090\ttotal: 352ms\tremaining: 0us\n",
      "0:\tlearn: 0.6071047\ttotal: 33.1ms\tremaining: 298ms\n",
      "1:\tlearn: 0.5445794\ttotal: 69.1ms\tremaining: 276ms\n",
      "2:\tlearn: 0.4940784\ttotal: 102ms\tremaining: 238ms\n",
      "3:\tlearn: 0.4579694\ttotal: 136ms\tremaining: 204ms\n",
      "4:\tlearn: 0.4231805\ttotal: 173ms\tremaining: 173ms\n",
      "5:\tlearn: 0.3972660\ttotal: 206ms\tremaining: 137ms\n",
      "6:\tlearn: 0.3713579\ttotal: 238ms\tremaining: 102ms\n",
      "7:\tlearn: 0.3533690\ttotal: 270ms\tremaining: 67.6ms\n",
      "8:\tlearn: 0.3348057\ttotal: 304ms\tremaining: 33.7ms\n",
      "9:\tlearn: 0.3211138\ttotal: 341ms\tremaining: 0us\n",
      "0:\tlearn: 0.6043867\ttotal: 34.9ms\tremaining: 314ms\n",
      "1:\tlearn: 0.5417567\ttotal: 67.8ms\tremaining: 271ms\n",
      "2:\tlearn: 0.4888872\ttotal: 101ms\tremaining: 235ms\n",
      "3:\tlearn: 0.4513229\ttotal: 136ms\tremaining: 204ms\n",
      "4:\tlearn: 0.4199214\ttotal: 169ms\tremaining: 169ms\n",
      "5:\tlearn: 0.3958163\ttotal: 206ms\tremaining: 137ms\n",
      "6:\tlearn: 0.3730539\ttotal: 242ms\tremaining: 104ms\n",
      "7:\tlearn: 0.3520823\ttotal: 277ms\tremaining: 69.3ms\n",
      "8:\tlearn: 0.3312766\ttotal: 313ms\tremaining: 34.7ms\n",
      "9:\tlearn: 0.3190789\ttotal: 346ms\tremaining: 0us\n",
      "0:\tlearn: 0.6029019\ttotal: 34.6ms\tremaining: 312ms\n",
      "1:\tlearn: 0.5422385\ttotal: 73ms\tremaining: 292ms\n",
      "2:\tlearn: 0.5026549\ttotal: 109ms\tremaining: 254ms\n",
      "3:\tlearn: 0.4629006\ttotal: 142ms\tremaining: 213ms\n",
      "4:\tlearn: 0.4291156\ttotal: 175ms\tremaining: 175ms\n",
      "5:\tlearn: 0.4029215\ttotal: 211ms\tremaining: 141ms\n",
      "6:\tlearn: 0.3805550\ttotal: 247ms\tremaining: 106ms\n",
      "7:\tlearn: 0.3604127\ttotal: 283ms\tremaining: 70.8ms\n",
      "8:\tlearn: 0.3446764\ttotal: 318ms\tremaining: 35.3ms\n",
      "9:\tlearn: 0.3273332\ttotal: 352ms\tremaining: 0us\n",
      "0:\tlearn: 0.6894236\ttotal: 869us\tremaining: 7.82ms\n",
      "1:\tlearn: 0.6862986\ttotal: 1.95ms\tremaining: 7.78ms\n",
      "2:\tlearn: 0.6831380\ttotal: 2.94ms\tremaining: 6.87ms\n",
      "3:\tlearn: 0.6800719\ttotal: 3.77ms\tremaining: 5.66ms\n",
      "4:\tlearn: 0.6768215\ttotal: 4.59ms\tremaining: 4.59ms\n",
      "5:\tlearn: 0.6737065\ttotal: 5.39ms\tremaining: 3.6ms\n",
      "6:\tlearn: 0.6707878\ttotal: 6.21ms\tremaining: 2.66ms\n",
      "7:\tlearn: 0.6677053\ttotal: 7.07ms\tremaining: 1.77ms\n",
      "8:\tlearn: 0.6648147\ttotal: 7.84ms\tremaining: 870us\n",
      "9:\tlearn: 0.6616786\ttotal: 8.73ms\tremaining: 0us\n",
      "0:\tlearn: 0.6894917\ttotal: 965us\tremaining: 8.69ms\n",
      "1:\tlearn: 0.6864560\ttotal: 2.04ms\tremaining: 8.17ms\n",
      "2:\tlearn: 0.6832474\ttotal: 2.94ms\tremaining: 6.86ms\n",
      "3:\tlearn: 0.6802786\ttotal: 3.75ms\tremaining: 5.63ms\n",
      "4:\tlearn: 0.6770452\ttotal: 4.64ms\tremaining: 4.64ms\n",
      "5:\tlearn: 0.6743545\ttotal: 5.55ms\tremaining: 3.7ms\n",
      "6:\tlearn: 0.6714304\ttotal: 6.37ms\tremaining: 2.73ms\n",
      "7:\tlearn: 0.6684943\ttotal: 7.14ms\tremaining: 1.78ms\n",
      "8:\tlearn: 0.6655598\ttotal: 7.95ms\tremaining: 883us\n",
      "9:\tlearn: 0.6624778\ttotal: 8.76ms\tremaining: 0us\n",
      "0:\tlearn: 0.6897975\ttotal: 858us\tremaining: 7.73ms\n",
      "1:\tlearn: 0.6867727\ttotal: 1.82ms\tremaining: 7.27ms\n",
      "2:\tlearn: 0.6834657\ttotal: 2.74ms\tremaining: 6.4ms\n",
      "3:\tlearn: 0.6802972\ttotal: 3.72ms\tremaining: 5.58ms\n",
      "4:\tlearn: 0.6768736\ttotal: 4.65ms\tremaining: 4.65ms\n",
      "5:\tlearn: 0.6737929\ttotal: 5.5ms\tremaining: 3.66ms\n",
      "6:\tlearn: 0.6707278\ttotal: 6.36ms\tremaining: 2.72ms\n",
      "7:\tlearn: 0.6675046\ttotal: 7.2ms\tremaining: 1.8ms\n",
      "8:\tlearn: 0.6644178\ttotal: 8ms\tremaining: 888us\n",
      "9:\tlearn: 0.6611730\ttotal: 8.83ms\tremaining: 0us\n",
      "0:\tlearn: 0.6895719\ttotal: 785us\tremaining: 7.07ms\n",
      "1:\tlearn: 0.6867922\ttotal: 1.62ms\tremaining: 6.49ms\n",
      "2:\tlearn: 0.6840498\ttotal: 2.58ms\tremaining: 6.02ms\n",
      "3:\tlearn: 0.6811063\ttotal: 3.49ms\tremaining: 5.23ms\n",
      "4:\tlearn: 0.6780049\ttotal: 4.46ms\tremaining: 4.46ms\n",
      "5:\tlearn: 0.6751736\ttotal: 5.72ms\tremaining: 3.82ms\n",
      "6:\tlearn: 0.6720132\ttotal: 6.73ms\tremaining: 2.88ms\n",
      "7:\tlearn: 0.6688939\ttotal: 7.58ms\tremaining: 1.89ms\n",
      "8:\tlearn: 0.6659463\ttotal: 8.42ms\tremaining: 935us\n",
      "9:\tlearn: 0.6628692\ttotal: 9.27ms\tremaining: 0us\n",
      "0:\tlearn: 0.6897493\ttotal: 895us\tremaining: 8.06ms\n",
      "1:\tlearn: 0.6867410\ttotal: 1.82ms\tremaining: 7.27ms\n",
      "2:\tlearn: 0.6835618\ttotal: 2.61ms\tremaining: 6.09ms\n",
      "3:\tlearn: 0.6805977\ttotal: 3.46ms\tremaining: 5.19ms\n",
      "4:\tlearn: 0.6773229\ttotal: 4.34ms\tremaining: 4.34ms\n",
      "5:\tlearn: 0.6740016\ttotal: 5.19ms\tremaining: 3.46ms\n",
      "6:\tlearn: 0.6714832\ttotal: 6.13ms\tremaining: 2.63ms\n",
      "7:\tlearn: 0.6686023\ttotal: 6.95ms\tremaining: 1.74ms\n",
      "8:\tlearn: 0.6656424\ttotal: 7.76ms\tremaining: 862us\n",
      "9:\tlearn: 0.6625231\ttotal: 8.64ms\tremaining: 0us\n",
      "0:\tlearn: 0.6645462\ttotal: 272ms\tremaining: 2.45s\n",
      "1:\tlearn: 0.6424819\ttotal: 549ms\tremaining: 2.19s\n",
      "2:\tlearn: 0.6214826\ttotal: 810ms\tremaining: 1.89s\n",
      "3:\tlearn: 0.6016799\ttotal: 1.09s\tremaining: 1.63s\n",
      "4:\tlearn: 0.5767249\ttotal: 1.36s\tremaining: 1.36s\n",
      "5:\tlearn: 0.5596539\ttotal: 1.64s\tremaining: 1.09s\n",
      "6:\tlearn: 0.5442696\ttotal: 2.13s\tremaining: 912ms\n",
      "7:\tlearn: 0.5278199\ttotal: 2.48s\tremaining: 620ms\n",
      "8:\tlearn: 0.5116938\ttotal: 2.77s\tremaining: 308ms\n",
      "9:\tlearn: 0.4997162\ttotal: 3.04s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=<catboost.core.CatBoostClassifier object at 0x7f790f39ca00>,\n",
       "                   param_distributions={'depth': [5, 7, 12, 15],\n",
       "                                        'iterations': [10, 12, 15, 20, 25],\n",
       "                                        'learning_rate': [0.1, 0.01, 0.3, 0.33],\n",
       "                                        'loss_function': ['Logloss']})"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cat_model = CatBoostClassifier()\n",
    "\n",
    "parameters = { 'iterations':[10,12,15,20,25],\n",
    "               'depth':[5,7,12,15],\n",
    "               'learning_rate':[0.1,0.01,0.3,0.33],\n",
    "               'loss_function':['Logloss'],\n",
    "             }\n",
    "\n",
    "model_catBoost = RandomizedSearchCV(estimator=cat_model, param_distributions=parameters)\n",
    "\n",
    "model_catBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad.rapidops.com/satyam.chatrola/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgBoost = XGBClassifier()\n",
    "model_xgBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xg_model = XGBClassifier()\n",
    "\n",
    "# parameters = { 'iterations':[10,12,15,20,25],\n",
    "#                'depth':[5,7,12,15],\n",
    "#                'learning_rate':[0.1,0.01,0.3,0.33],\n",
    "#                'loss_function':['Logloss'],\n",
    "#              }\n",
    "\n",
    "# model_xgBoost = RandomizedSearchCV(estimator=xg_model, param_distributions=parameters)\n",
    "\n",
    "# model_xgBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgBoost.predict([X_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgBoost.predict_proba([X_test[0]])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRFClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bytree=1, enable_categorical=False, gamma=0,\n",
       "                gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "                num_parallel_tree=100, objective='binary:logistic',\n",
       "                predictor='auto', random_state=0, reg_alpha=0,\n",
       "                scale_pos_weight=1, tree_method='exact', validate_parameters=1,\n",
       "                verbosity=None)"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "model_xgbrfc = XGBRFClassifier()\n",
    "model_xgbrfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgbrfc.predict([X_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgbrfc.predict_proba([X_test[0]])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_rfc.predict_proba([X_test[0]])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ann.predict(np.array([X_test[0]]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(inputValue):\n",
    "    if inputValue >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansTotalArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(paramList):\n",
    "    ans_RFC = format_output(model_rfc.predict_proba([paramList])[0][1])\n",
    "    ans_ANN = format_output(model_ann.predict(np.array([paramList]))[0][0])\n",
    "    ans_CB = format_output(model_catBoost.predict_proba(paramList)[1])\n",
    "    ans_XG = format_output(model_xgBoost.predict([paramList]))\n",
    "    ans_XGBRFC = format_output(model_xgbrfc.predict([paramList]))\n",
    "\n",
    "    ans_total = ans_RFC + ans_ANN + ans_CB + ans_XG + ans_XGBRFC\n",
    "    \n",
    "    ansTotalArray.append(ans_total)\n",
    "\n",
    "    if ans_total > 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ix in X_test:\n",
    "#     print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in X_test:\n",
    "    y_pred.append(predict_answer(i))\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n",
      "0.9224806201550387\n",
      "0.9311424100156495\n",
      "0.9444444444444443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ansTotalArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[245,  10],\n",
       "       [  4, 119]])"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "preds = y_pred\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603174603174603\n",
      "0.9029850746268657\n",
      "0.9180576631259484\n",
      "0.9416342412451362\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_xgBoost.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "preds = y_pred\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
